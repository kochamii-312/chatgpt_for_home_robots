import streamlit as st
import json
import os
import random
import joblib

from dotenv import load_dotenv

from api import client, SYSTEM_PROMPT, build_bootstrap_user_message
from jsonl import predict_with_model, save_experiment_1_result
from move_functions import (
    move_to,
    pick_object,
    place_object_next_to,
    place_object_on,
)
from run_and_show import (
    run_plan_and_show,
    show_clarifying_question,
    show_function_sequence,
)
from run_and_show import show_provisional_output
from strips import extract_between, strip_tags
from image_task_sets import (
    build_task_set_choices,
    extract_task_lines,
    load_image_task_sets,
    resolve_image_paths,
)

load_dotenv()

def app():
    st.title("LLMATCH Criticãƒ‡ãƒ¢ã‚¢ãƒ—ãƒª")
    st.subheader("å®Ÿé¨“1 GPTã¨GPT with Criticã®æ¯”è¼ƒ")
    
    st.sidebar.subheader("è¡Œå‹•è¨ˆç”»ã§ä½¿ç”¨ã•ã‚Œã‚‹é–¢æ•°")
    st.sidebar.markdown(
    """
    - **move_to(room_name:str)**  
    æŒ‡å®šã—ãŸéƒ¨å±‹ã¸ãƒ­ãƒœãƒƒãƒˆã‚’ç§»å‹•ã—ã¾ã™ã€‚

    - **pick_object(object:str)**  
    æŒ‡å®šã—ãŸç‰©ä½“ã‚’ã¤ã‹ã¿ã¾ã™ã€‚

    - **place_object_next_to(object:str, target:str)**  
    æŒ‡å®šã—ãŸç‰©ä½“ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®æ¨ªã«ç½®ãã¾ã™ã€‚

    - **place_object_on(object:str, target:str)**  
    æŒ‡å®šã—ãŸç‰©ä½“ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ä¸Šã«ç½®ãã¾ã™ã€‚

    - **place_object_in(object:str, target:str)**  
    æŒ‡å®šã—ãŸç‰©ä½“ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ä¸­ã«å…¥ã‚Œã¾ã™ã€‚

    - **detect_object(object:str)**  
    æŒ‡å®šã—ãŸç‰©ä½“ã‚’æ¤œå‡ºã—ã¾ã™ã€‚

    - **search_about(object:str)**  
    æŒ‡å®šã—ãŸç‰©ä½“ã«é–¢ã™ã‚‹æƒ…å ±ã‚’æ¤œç´¢ã—ã¾ã™ã€‚

    - **push(object:str)**  
    æŒ‡å®šã—ãŸç‰©ä½“ã‚’æŠ¼ã—ã¾ã™ã€‚

    - **say(text:str)**  
    æŒ‡å®šã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ç™ºè©±ã—ã¾ã™ã€‚
    """
    )

    mode_options = ["GPT", "GPT with critic"]
    default_mode = st.session_state.get("mode", "GPT with critic")
    mode = st.radio("ãƒ¢ãƒ¼ãƒ‰é¸æŠ", mode_options, index=mode_options.index(default_mode), horizontal=True)
    st.session_state["mode"] = mode

    system_prompt = SYSTEM_PROMPT
    
    with st.expander("è©•ä¾¡ãƒ¢ãƒ‡ãƒ«ãƒ»ã‚¿ã‚¹ã‚¯èª¿æ•´ï¼ˆä»»æ„ï¼‰", expanded=False):
        model_files = sorted(
            f for f in os.listdir("models") if f.endswith(".joblib")
        )
        if model_files:
            latest_model = max(
                model_files,
                key=lambda f: os.path.getmtime(os.path.join("models", f)),
            )
            stored_model = st.session_state.get("model_path")
            current_model = os.path.basename(stored_model) if stored_model else None
            if current_model not in model_files:
                current_model = latest_model
            selected_model = st.selectbox(
                "è©•ä¾¡ãƒ¢ãƒ‡ãƒ«ï¼ˆè‡ªå‹•ï¼‰",
                model_files,
                index=model_files.index(current_model),
            )
            st.session_state["model_path"] = os.path.join("models", selected_model)

        task_sets = load_image_task_sets()
        if not task_sets:
            st.warning("å†™çœŸã¨ã‚¿ã‚¹ã‚¯ã®ã‚»ãƒƒãƒˆãŒä¿å­˜ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã¾ãšã€å†™çœŸã¨ã‚¿ã‚¹ã‚¯ã®é¸å®šãƒ»ä¿å­˜ã€ãƒšãƒ¼ã‚¸ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚")
            st.session_state["selected_image_paths"] = []
            st.session_state["experiment1_selected_task_set"] = None
        else:
            choice_pairs = build_task_set_choices(task_sets)
            labels = [label for label, _ in choice_pairs]
            label_to_key = {label: key for label, key in choice_pairs}

            if not labels:
                st.warning("ä¿å­˜æ¸ˆã¿ã®ã‚¿ã‚¹ã‚¯ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
                st.session_state["selected_image_paths"] = []
                st.session_state["experiment1_selected_task_set"] = None
                payload = {}
            else:
                stored_label = st.session_state.get("experiment1_selected_task_label")
                if stored_label not in labels:
                    stored_label = random.choice(labels)
                selected_label = st.selectbox(
                    "ã‚¿ã‚¹ã‚¯",
                    labels,
                    index=labels.index(stored_label),
                )
                st.session_state["experiment1_selected_task_label"] = selected_label
                selected_task_name = label_to_key.get(selected_label)
                st.session_state["experiment1_selected_task_set"] = selected_task_name
                payload = task_sets.get(selected_task_name, {}) if selected_task_name else {}

        house = payload.get("house") if isinstance(payload, dict) else ""
        room = payload.get("room") if isinstance(payload, dict) else ""
        meta_lines = []

        task_lines = extract_task_lines(payload)

    st.markdown("### æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚¹ã‚¯")
    if task_lines:
        for line in task_lines:
            st.info(f"{line}")
    else:
        st.info("ã‚¿ã‚¹ã‚¯ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.write("â†’æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ã‚’ãã®ã¾ã¾ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«å…¥åŠ›ã—ã¦ãã ã•ã„ï¼")

    image_candidates = []
    if isinstance(payload, dict):
        image_candidates = [str(p) for p in payload.get("images", []) if isinstance(p, str)]

    existing_images, missing_images = resolve_image_paths(image_candidates)

    st.session_state["selected_image_paths"] = existing_images

    if missing_images:
        st.warning(
            "ä»¥ä¸‹ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: " + ", ".join(missing_images)
        )

    st.markdown("### æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ãŒè¡Œã‚ã‚Œã‚‹å ´æ‰€")
    if house:
        meta_lines.append(f"å®¶: {house}")
    if room:
        meta_lines.append(f"éƒ¨å±‹: {room}")
    if meta_lines:
        st.write(" / ".join(meta_lines))
    if existing_images:
        for path in existing_images:
            st.image(path, caption=os.path.basename(path))
    else:
        st.info("ç”»åƒãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    # 1) ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆæœŸåŒ–ï¼ˆsystemã ã‘å…ˆã«å…¥ã‚Œã¦ä¿æŒï¼‰
    if (
        "context" not in st.session_state
        or st.session_state.get("system_prompt") != system_prompt
    ):
        st.session_state["context"] = [{"role": "system", "content": system_prompt}]
        st.session_state["system_prompt"] = system_prompt
        st.session_state.conv_log = {
            "information": "",
            "label": "",
            "clarifying_steps": []
        }
        st.session_state.turn_count = 0
        st.session_state["chat_input_history"] = []
    if "chat_input_history" not in st.session_state:
        st.session_state["chat_input_history"] = []
    if "active" not in st.session_state:
        st.session_state.active = True
    if "turn_count" not in st.session_state:
        st.session_state.turn_count = 0
    if "force_end" not in st.session_state:
        st.session_state.force_end = False
    if "end_reason" not in st.session_state:
        st.session_state.end_reason = ""

    st.markdown("### ãƒ­ãƒœãƒƒãƒˆã¨ã®ä¼šè©±")
    context = st.session_state["context"]

    message = st.chat_message("assistant")
    message.write("ã“ã‚“ã«ã¡ã¯ã€ç§ã¯å®¶åº­ç”¨ãƒ­ãƒœãƒƒãƒˆã§ã™ï¼ã‚ãªãŸã®æŒ‡ç¤ºã«å¾“ã£ã¦è¡Œå‹•ã—ã¾ã™ã€‚")
    if st.session_state.get("force_end"):
        user_input = None
    else:
        input_box = st.chat_input("ãƒ­ãƒœãƒƒãƒˆã¸ã®å›ç­”ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        if input_box:
            st.session_state["chat_input_history"].append(input_box)
        user_input = st.session_state.pop("pending_user_input", None) or input_box
    
    if user_input:
        context.append({"role": "user", "content": user_input})
        selected_paths = st.session_state.get("selected_image_paths", [])
        if selected_paths:
            context.append(
                build_bootstrap_user_message(
                    text="Here are the selected images. Use them for scene understanding and disambiguation.",
                    local_image_paths=selected_paths,
                )
            )
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=context
        )
        reply = response.choices[0].message.content.strip()
        print("Assistant:", reply)
        context.append({"role": "assistant", "content": reply})
        print("context: ", context)
        st.session_state.turn_count += 1
        
    # ç”»é¢ä¸‹éƒ¨ã«å±¥æ­´ã‚’å…¨è¡¨ç¤ºï¼ˆsystemã¯çœãï¼‰
    last_assistant_idx = max((i for i, m in enumerate(context) if m["role"] == "assistant"), default=None)
    
    for i, msg in enumerate(context):
        if msg["role"] == "system":
            continue
        with st.chat_message(msg["role"]):
            st.write(msg["content"])
            if msg["role"] == "assistant":
                if i == last_assistant_idx and "<FunctionSequence>" in msg["content"]:
                    run_plan_and_show(msg["content"])
                show_function_sequence(msg["content"])
                show_clarifying_question(msg["content"])
    assistant_messages = [m for m in context if m["role"] == "assistant"]
    if assistant_messages:
        label, p, th = predict_with_model()
        st.caption(f"è©•ä¾¡ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬: {label} (p={p:.3f}, th={th:.3f})")
    else:
        label, p, th = None, None, None
        st.caption("è©•ä¾¡ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬: ---")

    last_assistant_content = assistant_messages[-1]["content"] if assistant_messages else ""
    has_plan = "<FunctionSequence>" in last_assistant_content
    high_conf = (p is not None and th is not None and p >= th + 0.15)

    should_stop = False
    end_message = ""
    if st.session_state.get("force_end"):
        should_stop = True
        end_message = "ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä¼šè©±ã‚’å¼·åˆ¶çš„ã«çµ‚äº†ã—ã¾ã—ãŸã€‚"
    elif st.session_state.get("mode") == "GPT with critic":
        if label == "sufficient" and (has_plan or high_conf or st.session_state.turn_count >= 2):
            should_stop = True
            end_message = "ãƒ¢ãƒ‡ãƒ«ãŒsufficientã‚’å‡ºåŠ›ã—ãŸãŸã‚çµ‚äº†ã—ã¾ã™ã€‚"
    else:
        if st.session_state.turn_count >= 4:
            should_stop = True
            end_message = "4å›ã®ä¼šè©±ã«é”ã—ãŸãŸã‚çµ‚äº†ã—ã¾ã™ã€‚"

    if should_stop:
        st.success(end_message)
        if st.session_state.active:
            with st.form("evaluation_form"):
                name = st.text_input(
                    "ã‚ãªãŸã®åå‰ã‚„ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒãƒ¼ãƒ ç­‰ï¼ˆè¢«é¨“è€…åŒºåˆ¥ç”¨ï¼‰"
                )
                success = st.radio(
                    "è¡Œå‹•è¨ˆç”»ãŒå®Ÿè¡Œã•ã‚ŒãŸã¨ã—ã¦ã€ãƒ­ãƒœãƒƒãƒˆã¯æˆåŠŸã—ã¾ã™ã‹ï¼Ÿ", 
                    ["æˆåŠŸã™ã‚‹", "æˆåŠŸã—ãªã„"], 
                    horizontal=True
                )
                failure_reason = st.multiselect(
                    "æˆåŠŸã—ãªã„å ´åˆã€ãã®ç†ç”±ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰",
                    [
                        "é–¢æ•°ãŒä¸é©åˆ‡ãƒ»ä¸è¶³ã—ã¦ã„ã‚‹",
                        "å¤‰æ•°ãŒä¸é©åˆ‡ãƒ»å…·ä½“çš„ã§ãªã„",
                        "è™šå½ã®æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹",
                        "ä¼šè©±ã®ä¸­ã§å‡ºã¦ããŸå¿…è¦ãªæƒ…å ±ã‚’å«ã‚“ã§ã„ãªã„",
                        "è¤‡æ•°ã®ã‚‚ã®ãŒã‚ã‚‹ä¸­ã§é©åˆ‡ãªã‚‚ã®ãŒé¸ã¹ãªã„",
                        "ä»¥ä¸Šã®ç†ç”±ä»¥å¤–", 
                        "æˆåŠŸã™ã‚‹"
                    ]
                )
                failure_reason_others = st.text_input(
                    "å‰ã®è³ªå•ã§ã€Œä»¥ä¸Šã®ç†ç”±ä»¥å¤–ã€ã‚’é¸ã‚“ã æ–¹ã¯ãã®å†…å®¹ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚"
                )
                grices_maxim = st.multiselect(
                    "ãƒ­ãƒœãƒƒãƒˆã®ç™ºè¨€ã«é–¢ã—ã¦ã€ä»¥ä¸‹ã®å†…å®¹ã®ä¸­ã§å½“ã¦ã¯ã¾ã‚‹ã‚‚ã®ãŒã‚ã‚Œã°é¸ã‚“ã§ãã ã•ã„ã€‚ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰",
                    [
                        "å˜˜ã‚„è™šå½ã®æƒ…å ±ã‚’è¿°ã¹ãŸ",
                        "è³ªå•ãƒ»æƒ…å ±æä¾›ãŒå¤šã™ãã‚‹ã¾ãŸã¯å°‘ãªã™ãã‚‹",
                        "ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ã®ã«é–¢ä¿‚ã®ãªã„ç™ºè¨€ãŒã‚ã£ãŸ",
                        "ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒæ˜ç¢ºã§ãªã‹ã£ãŸï¼ˆä½•ã¨ç­”ãˆã‚Œã°ã„ã„ã‹ã‚ã‹ã‚‰ãªã„è³ªå•ãŒã‚ã£ãŸç­‰ï¼‰"
                    ]
                )
                familiarity = st.radio(
                    "ãƒ­ãƒœãƒƒãƒˆã«ã©ã‚Œãã‚‰ã„è¦ªè¿‘æ„Ÿã‚’æŒã¡ã¾ã—ãŸã‹ï¼Ÿï¼ˆ1-4ï¼‰",
                    [1, 2, 3, 4],
                    horizontal=True
                )
                social_presence = st.radio(
                    "å¯¾è©±ã®ç›¸æ‰‹ãŒãã“ã«å­˜åœ¨ã—ã€è‡ªåˆ†ã¨åŒã˜ç©ºé–“ã‚’å…±æœ‰ã—ã¦ã„ã‚‹ã€ã‚ã‚‹ã„ã¯è‡ªåˆ†ã¨é–¢ã‚ã£ã¦ã„ã‚‹æ„Ÿè¦šï¼ˆã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ—ãƒ¬ã‚¼ãƒ³ã‚¹ï¼‰ã‚’ã©ã‚Œãã‚‰ã„æŒã¡ã¾ã—ãŸã‹ï¼Ÿï¼ˆ1-4ï¼‰",
                    [1, 2, 3, 4],
                    horizontal=True
                )
                free = st.text_input(
                    "ãã®ä»–ã«ä½•ã‹æ„Ÿã˜ãŸã“ã¨ãŒã‚ã‚Œã°ãŠé¡˜ã„ã—ã¾ã™ã€‚"
                )
                submitted = st.form_submit_button("è©•ä¾¡ã‚’ä¿å­˜")

            if submitted:
                scores = {
                    "name": name,
                    "success": success,
                    "failure_reason": failure_reason,
                    "failure_reason_others": failure_reason_others,
                    "grices_maxim": grices_maxim,
                    "familiarity": familiarity,
                    "social_presence": social_presence,
                    "free": free,
                }
                termination_label = "ä¼šè©±ã‚’å¼·åˆ¶çš„ã«çµ‚äº†" if st.session_state.get("force_end") else ""
                save_experiment_1_result(
                    scores,
                    st.session_state.get("end_reason", ""),
                    termination_label,
                )
                st.session_state.active = False

        if st.session_state.active == False:
            st.warning("ä¼šè©±ã‚’çµ‚äº†ã—ã¾ã—ãŸã€‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸï¼")
            cols_end = st.columns([1, 1, 2])
            with cols_end[0]:
                if st.button("âš ï¸ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆ", key="reset_conv_end"):
                    st.session_state.context = [{"role": "system", "content": system_prompt}]
                    st.session_state.active = True
                    st.session_state.conv_log = {
                        "label": "",
                        "clarifying_steps": []
                    }
                    st.session_state.saved_jsonl = []
                    st.session_state.turn_count = 0
                    st.session_state.force_end = False
                    st.session_state.end_reason = ""
                    st.session_state["chat_input_history"] = []
                    st.rerun()
            with cols_end[1]:
                st.button("ğŸš¨ä¼šè©±ã‚’å¼·åˆ¶çš„ã«çµ‚äº†", key="force_end_disabled", disabled=True)
            with cols_end[2]:
                st.text_input("ä¼šè©±ã‚’çµ‚äº†ã—ãŸã„ç†ç”±", key="end_reason", disabled=True)
            st.stop()

    cols = st.columns([1, 1, 2])
    with cols[0]:
        if st.button("âš ï¸ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆ", key="reset_conv"):
            st.session_state.context = [{"role": "system", "content": system_prompt}]
            st.session_state.active = True
            st.session_state.conv_log = {
                "label": "",
                "clarifying_steps": []
            }
            st.session_state.saved_jsonl = []
            st.session_state.turn_count = 0
            st.session_state.force_end = False
            st.session_state.end_reason = ""
            st.session_state["chat_input_history"] = []
            st.rerun()
    with cols[1]:
        if st.button("ğŸš¨ä¼šè©±ã‚’å¼·åˆ¶çš„ã«çµ‚äº†", key="force_end_button"):
            st.session_state.force_end = True
            st.session_state.end_reason = st.session_state.get("end_reason", "")
            st.rerun()
    with cols[2]:
        st.text_input("ä¼šè©±ã‚’çµ‚äº†ã—ãŸã„ç†ç”±", key="end_reason")

app()
