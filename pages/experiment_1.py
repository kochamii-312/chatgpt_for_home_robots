import streamlit as st
import streamlit.components.v1 as components
from consent import (
    apply_sidebar_hiding,
    configure_page,
    require_consent,
    should_hide_sidebar,
)
import json
import os
import random
import joblib

from dotenv import load_dotenv

from api import client, SYSTEM_PROMPT, build_bootstrap_user_message
from jsonl import predict_with_model, save_experiment_1_result
from move_functions_ import (
    move_to,
    pick_object,
    place_object_next_to,
    place_object_on,
)
from run_and_show import (
    run_plan_and_show,
    show_clarifying_question,
    show_function_sequence,
)
from run_and_show import show_provisional_output
from strips import extract_between, strip_tags
from image_task_sets import (
    build_task_set_choices,
    extract_task_lines,
    load_image_task_sets,
    resolve_image_paths,
)

load_dotenv()


configure_page(hide_sidebar_for_participant=True)


SCROLL_RESET_FLAG_KEY = "experiment1_scroll_reset_done"
ACTIVE_PAGE_STATE_KEY = "current_active_page"
ACTIVE_PAGE_VALUE = "experiment_1"


def _scroll_to_top_on_first_load() -> None:
    if st.session_state.get(ACTIVE_PAGE_STATE_KEY) != ACTIVE_PAGE_VALUE:
        st.session_state.pop(SCROLL_RESET_FLAG_KEY, None)

    if not st.session_state.get(SCROLL_RESET_FLAG_KEY):
        components.html(
            """
            <script>
            const doc = window.parent ? window.parent.document : document;
            const main = doc ? doc.querySelector('section.main') : null;
            if (main) {
                main.scrollTo(0, 0);
            } else {
                window.scrollTo(0, 0);
            }
            </script>
            """,
            height=0,
        )
        st.session_state[SCROLL_RESET_FLAG_KEY] = True

    st.session_state[ACTIVE_PAGE_STATE_KEY] = ACTIVE_PAGE_VALUE

def _reset_conversation_state(system_prompt: str) -> None:
    """Reset conversation-related session state for experiment 1."""

    st.session_state.context = [{"role": "system", "content": system_prompt}]
    st.session_state.active = True
    st.session_state.conv_log = {
        "label": "",
        "clarifying_steps": []
    }
    st.session_state.saved_jsonl = []
    st.session_state.turn_count = 0
    st.session_state.force_end = False
    # st.session_state.end_reason = []
    st.session_state["chat_input_history"] = []
    st.session_state["experiment1_followup_prompt"] = False
    st.session_state.pop("experiment1_followup_choice", None)
    _update_random_task_selection(
        "experiment1_selected_task_label",
        "experiment1_task_labels",
        "experiment1_label_to_key",
        "experiment1_selected_task_set",
    )


def _update_random_task_selection(label_key: str, labels_key: str, mapping_key: str, set_key: str) -> None:
    """Select a new task label at random and update related session state."""

    labels = st.session_state.get(labels_key) or []
    if not labels:
        return

    current_label = st.session_state.get(label_key)
    candidates = [label for label in labels if label != current_label] or labels
    new_label = random.choice(candidates)

    st.session_state[label_key] = new_label
    label_to_key = st.session_state.get(mapping_key) or {}
    st.session_state[set_key] = label_to_key.get(new_label)


def app():
    require_consent()
    _scroll_to_top_on_first_load()
    # st.title("LLMATCH Criticãƒ‡ãƒ¢ã‚¢ãƒ—ãƒª")
    st.markdown("### å®Ÿé¨“1 GPTã¨GPT with Critic")

    if should_hide_sidebar():
        apply_sidebar_hiding()

    mode_options = ["GPT", "GPT with critic"]
    default_mode = st.session_state.get("mode", "GPT with critic")
    mode = st.radio("### â‘ ãƒ¢ãƒ¼ãƒ‰é¸æŠ", mode_options, index=mode_options.index(default_mode), horizontal=True)
    st.session_state["mode"] = mode

    st.write("â€»ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¦ã‚‚ã“ã®é¸æŠã¯å¤‰ã‚ã‚Šã¾ã›ã‚“ã€‚")
    st.session_state.setdefault("critic_min_threshold", 0.60)
    
    system_prompt = SYSTEM_PROMPT
    
    with st.expander("è©•ä¾¡ãƒ¢ãƒ‡ãƒ«ãƒ»ã‚¿ã‚¹ã‚¯èª¿æ•´ï¼ˆä»»æ„ï¼‰", expanded=False):
        model_files = sorted(
            f for f in os.listdir("models") if f.endswith(".joblib")
        )
        if model_files:
            latest_model = max(
                model_files,
                key=lambda f: os.path.getmtime(os.path.join("models", f)),
            )
            stored_model = st.session_state.get("model_path")
            current_model = os.path.basename(stored_model) if stored_model else None
            if current_model not in model_files:
                current_model = latest_model
            selected_model = st.selectbox(
                "è©•ä¾¡ãƒ¢ãƒ‡ãƒ«ï¼ˆè‡ªå‹•ï¼‰",
                model_files,
                index=model_files.index(current_model),
            )
            st.session_state["model_path"] = os.path.join("models", selected_model)
        st.session_state["critic_min_threshold"] = st.slider("critic_min_threshold", 0.5, 0.9, 0.60, 0.01)
        st.session_state["critic_margin"]       = st.slider("critic_margin", 0.0, 0.3, 0.15, 0.01)
        
        use_force = st.checkbox("ã—ãã„å€¤ã‚’ä¸Šæ›¸ãã™ã‚‹ï¼ˆforceï¼‰", value=True)
        if use_force:
            st.session_state["critic_force_threshold"] = st.slider("force_threshold", 0.50, 0.90, 0.60, 0.01)
        else:
            st.session_state.pop("critic_force_threshold", None)

        task_sets = load_image_task_sets()
        if not task_sets:
            st.warning("å†™çœŸã¨ã‚¿ã‚¹ã‚¯ã®ã‚»ãƒƒãƒˆãŒä¿å­˜ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã¾ãšã€å†™çœŸã¨ã‚¿ã‚¹ã‚¯ã®é¸å®šãƒ»ä¿å­˜ã€ãƒšãƒ¼ã‚¸ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚")
            st.session_state["selected_image_paths"] = []
            st.session_state["experiment1_selected_task_set"] = None
            st.session_state["experiment1_task_labels"] = []
            st.session_state["experiment1_label_to_key"] = {}
        else:
            choice_pairs = build_task_set_choices(task_sets)
            labels = [label for label, _ in choice_pairs]
            label_to_key = {label: key for label, key in choice_pairs}

            st.session_state["experiment1_task_labels"] = labels
            st.session_state["experiment1_label_to_key"] = label_to_key

            if not labels:
                st.warning("ä¿å­˜æ¸ˆã¿ã®ã‚¿ã‚¹ã‚¯ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
                st.session_state["selected_image_paths"] = []
                st.session_state["experiment1_selected_task_set"] = None
                st.session_state["experiment1_task_labels"] = []
                st.session_state["experiment1_label_to_key"] = {}
                payload = {}
            else:
                stored_label = st.session_state.get("experiment1_selected_task_label")
                if stored_label not in labels:
                    stored_label = random.choice(labels)
                selected_label = st.selectbox(
                    "ã‚¿ã‚¹ã‚¯",
                    labels,
                    index=labels.index(stored_label),
                )
                st.session_state["experiment1_selected_task_label"] = selected_label
                selected_task_name = label_to_key.get(selected_label)
                st.session_state["experiment1_selected_task_set"] = selected_task_name
                payload = task_sets.get(selected_task_name, {}) if selected_task_name else {}

        house = payload.get("house") if isinstance(payload, dict) else ""
        room = payload.get("room") if isinstance(payload, dict) else ""
        meta_lines = []

        task_lines = extract_task_lines(payload)

    st.markdown("#### â‘¡æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚¹ã‚¯")
    st.write("ä¸‹ã®ã‚¿ã‚¹ã‚¯ã‚’ãã®ã¾ã¾ç”»é¢ä¸‹éƒ¨ã®ãƒãƒ£ãƒƒãƒˆã«å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    if task_lines:
        for line in task_lines:
            st.info(f"{line}")
    else:
        st.info("ã‚¿ã‚¹ã‚¯ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    image_candidates = []
    if isinstance(payload, dict):
        image_candidates = [str(p) for p in payload.get("images", []) if isinstance(p, str)]

    existing_images, missing_images = resolve_image_paths(image_candidates)

    st.session_state["selected_image_paths"] = existing_images

    if missing_images:
        st.warning(
            "ä»¥ä¸‹ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: " + ", ".join(missing_images)
        )

    st.markdown("#### â‘¢æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ã‚’è¡Œã†å ´æ‰€")
    if house:
        meta_lines.append(f"å®¶: {house}")
    if room:
        meta_lines.append(f"éƒ¨å±‹: {room}")
    if meta_lines:
        st.write(" / ".join(meta_lines))
    if existing_images:
        for path in existing_images:
            st.image(path, caption=os.path.basename(path))
    else:
        st.info("ç”»åƒãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    # 1) ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆæœŸåŒ–ï¼ˆsystemã ã‘å…ˆã«å…¥ã‚Œã¦ä¿æŒï¼‰
    if (
        "context" not in st.session_state
        or st.session_state.get("system_prompt") != system_prompt
    ):
        st.session_state["context"] = [{"role": "system", "content": system_prompt}]
        st.session_state["system_prompt"] = system_prompt
        st.session_state.conv_log = {
            "information": "",
            "label": "",
            "clarifying_steps": []
        }
        st.session_state.turn_count = 0
        st.session_state["chat_input_history"] = []
    if "chat_input_history" not in st.session_state:
        st.session_state["chat_input_history"] = []
    if "active" not in st.session_state:
        st.session_state.active = True
    if "turn_count" not in st.session_state:
        st.session_state.turn_count = 0
    if "force_end" not in st.session_state:
        st.session_state.force_end = False
    if "end_reason" not in st.session_state:
        st.session_state.end_reason = []
    if "experiment1_followup_prompt" not in st.session_state:
        st.session_state["experiment1_followup_prompt"] = False

    st.markdown("#### â‘£ãƒ­ãƒœãƒƒãƒˆã¨ã®ä¼šè©±")
    st.write("ã“ã®ä¸‹ã«ãƒ­ãƒœãƒƒãƒˆã‹ã‚‰ã®è³ªå•ãŒè¡¨ç¤ºã•ã‚Œã‚‹ã®ã§ã€â‘¢ã®å†™çœŸã‚’è¦‹ãªãŒã‚‰è³ªå•ã«å¯¾ã—ã¦ç­”ãˆã¦ãã ã•ã„ã€‚"
             "è³ªå•ã•ã‚ŒãŸæƒ…å ±ãŒå†™çœŸã«ãªã„å ´åˆã¯ã€\"ä»®æƒ³ã®æƒ…å ±\"ã‚’ç­”ãˆã¦æ§‹ã„ã¾ã›ã‚“ã€‚"
             "è‡ªå‹•ã§è©•ä¾¡ãƒ•ã‚©ãƒ¼ãƒ ãŒè¡¨ç¤ºã•ã‚Œã‚‹ã¾ã§ä¼šè©±ã‚’ç¶šã‘ã¦ãã ã•ã„ã€‚")
    context = st.session_state["context"]

    message = st.chat_message("assistant")
    message.write("ã“ã‚“ã«ã¡ã¯ã€ç§ã¯å®¶åº­ç”¨ãƒ­ãƒœãƒƒãƒˆã§ã™ï¼ã‚ãªãŸã®æŒ‡ç¤ºã«å¾“ã£ã¦è¡Œå‹•ã—ã¾ã™ã€‚")

    max_turns = 5
    should_stop = False
    label, p, th = None, None, None

    # å…¥åŠ›æ¬„ã®è¡¨ç¤ºåˆ¶å¾¡
    if should_stop:
        user_input = None
    elif st.session_state.get("force_end"):
        user_input = None
    elif st.session_state.get("mode") == "GPT" and st.session_state.turn_count >= max_turns:
        st.info(f"{max_turns}å›ã®æ“ä½œã«é”ã—ãŸãŸã‚ã€ã“ã‚Œä»¥ä¸Šå…¥åŠ›ã§ãã¾ã›ã‚“ã€‚ï¼ˆGPTãƒ¢ãƒ¼ãƒ‰ã®ã¿åˆ¶é™ï¼‰")
        user_input = None
    else:
        input_box = st.chat_input("ãƒ­ãƒœãƒƒãƒˆã¸ã®å›ç­”ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", key="experiment_1_chat_input")
        if input_box:
            st.session_state["chat_input_history"].append(input_box)
        user_input = st.session_state.pop("pending_user_input", None) or input_box

    if user_input:
        context.append({"role": "user", "content": user_input})
        selected_paths = st.session_state.get("selected_image_paths", [])
        if selected_paths:
            context.append(
                build_bootstrap_user_message(
                    text="Here are the selected images. Use them for scene understanding and disambiguation.",
                    local_image_paths=selected_paths,
                )
            )
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=context
        )
        reply = response.choices[0].message.content.strip()
        print("Assistant:", reply)
        context.append({"role": "assistant", "content": reply})
        print("context: ", context)
        st.session_state.turn_count += 1
        
    # ç”»é¢ä¸‹éƒ¨ã«å±¥æ­´ã‚’å…¨è¡¨ç¤ºï¼ˆsystemã¯çœãï¼‰
    last_assistant_idx = max((i for i, m in enumerate(context) if m["role"] == "assistant"), default=None)
    
    for i, msg in enumerate(context):
        if msg["role"] == "system":
            continue
        with st.chat_message(msg["role"]):
            st.write(msg["content"])
            if msg["role"] == "assistant":
                if i == last_assistant_idx and "<FunctionSequence>" in msg["content"]:
                    run_plan_and_show(msg["content"])
                show_function_sequence(msg["content"])
                show_clarifying_question(msg["content"])
    assistant_messages = [m for m in context if m["role"] == "assistant"]
    if assistant_messages:
        label, p, th = predict_with_model()
        st.caption(f"è©•ä¾¡ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬: {label} (p={p:.3f}, th={th:.3f})")
    else:
        st.caption("è©•ä¾¡ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬: ---")

    last_assistant_content = assistant_messages[-1]["content"] if assistant_messages else ""
    has_plan = "<FunctionSequence>" in last_assistant_content
    high_conf = (p is not None and th is not None and p >= th + 0.15)

    should_stop = False
    end_message = ""
    if st.session_state.get("force_end"):
        should_stop = True
        end_message = "ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä¼šè©±ã‚’çµ‚äº†ã—ã¾ã—ãŸã€‚"
    elif st.session_state.get("mode") == "GPT with critic":
        if label == "sufficient" and (has_plan or high_conf or st.session_state.turn_count >= 2):
            should_stop = True
            end_message = "ãƒ¢ãƒ‡ãƒ«ãŒsufficientã‚’å‡ºåŠ›ã—ãŸãŸã‚çµ‚äº†ã—ã¾ã™ã€‚"
    else:
        if st.session_state.turn_count >= 4:
            should_stop = True
            end_message = "4å›ã®ä¼šè©±ã«é”ã—ãŸãŸã‚çµ‚äº†ã—ã¾ã™ã€‚"

    if should_stop:
        if st.session_state.active == True:
            st.success(end_message)
            with st.form("evaluation_form"):
                st.subheader("â‘¤è©•ä¾¡ãƒ•ã‚©ãƒ¼ãƒ ")
                name = st.text_input(
                    "ã‚ãªãŸã®åå‰ã‚„ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒãƒ¼ãƒ ç­‰ï¼ˆè¢«é¨“è€…åŒºåˆ¥ç”¨ï¼‰"
                )
                success = st.radio(
                    "è¡Œå‹•è¨ˆç”»ãŒå®Ÿè¡Œã•ã‚ŒãŸã¨ã—ã¦ã€ãƒ­ãƒœãƒƒãƒˆã¯æˆåŠŸã—ã¾ã™ã‹ï¼Ÿ", 
                    ["æˆåŠŸã™ã‚‹", "æˆåŠŸã—ãªã„"], 
                    horizontal=True
                )
                failure_reason = st.multiselect(
                    "æˆåŠŸã—ãªã„å ´åˆã€ãã®ç†ç”±ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰",
                    [
                        "é–¢æ•°ãŒä¸é©åˆ‡ãƒ»ä¸è¶³ã—ã¦ã„ã‚‹",
                        "å¤‰æ•°ãŒä¸é©åˆ‡ãƒ»å…·ä½“çš„ã§ãªã„",
                        "è™šå½ã®æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹",
                        "ä¼šè©±ã®ä¸­ã§å‡ºã¦ããŸå¿…è¦ãªæƒ…å ±ã‚’å«ã‚“ã§ã„ãªã„",
                        "è¤‡æ•°ã®ã‚‚ã®ãŒã‚ã‚‹ä¸­ã§é©åˆ‡ãªã‚‚ã®ãŒé¸ã¹ãªã„",
                        "ä»¥ä¸Šã®ç†ç”±ä»¥å¤–", 
                        "æˆåŠŸã™ã‚‹",
                    ]
                )
                failure_reason_others = st.text_input(
                    "å‰ã®è³ªå•ã§ã€Œä»¥ä¸Šã®ç†ç”±ä»¥å¤–ã€ã‚’é¸ã‚“ã æ–¹ã¯ãã®å†…å®¹ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚"
                )
                grices_maxim = st.multiselect(
                    "ãƒ­ãƒœãƒƒãƒˆã®ç™ºè¨€ã«é–¢ã—ã¦ã€ä»¥ä¸‹ã®å†…å®¹ã®ä¸­ã§å½“ã¦ã¯ã¾ã‚‹ã‚‚ã®ãŒã‚ã‚Œã°é¸ã‚“ã§ãã ã•ã„ã€‚ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰",
                    [
                        "å˜˜ã‚„è™šå½ã®æƒ…å ±ã‚’è¿°ã¹ãŸ",
                        "è³ªå•ãƒ»æƒ…å ±æä¾›ãŒå¤šã™ãã‚‹ã¾ãŸã¯å°‘ãªã™ãã‚‹",
                        "ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ã®ã«é–¢ä¿‚ã®ãªã„ç™ºè¨€ãŒã‚ã£ãŸ",
                        "ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒæ˜ç¢ºã§ãªã‹ã£ãŸï¼ˆä½•ã¨ç­”ãˆã‚Œã°ã„ã„ã‹ã‚ã‹ã‚‰ãªã„è³ªå•ãŒã‚ã£ãŸç­‰ï¼‰",
                        "ç‰¹ã«ãªã—",
                    ]
                )
                kindness = st.radio(
                    "ãƒ­ãƒœãƒƒãƒˆã¯ã‚ãªãŸã«å¯¾ã—ã¦ã©ã‚Œãã‚‰ã„ã€Œè¦ªåˆ‡ã•/ä¸å¯§ã•ã€ã‚’æŒã£ã¦æ¥ã—ã¦ã„ã¾ã—ãŸã‹ï¼Ÿ",
                    ["éå¸¸ã«è¦ªåˆ‡ã ã£ãŸ", "ã¾ã‚ã¾ã‚è¦ªåˆ‡ã ã£ãŸ", "ã©ã¡ã‚‰ã¨ã‚‚ã„ãˆãªã„", "ã‚ã¾ã‚Šè¦ªåˆ‡ã§ãªã‹ã£ãŸ", "å…¨ãè¦ªåˆ‡ã§ãªã‹ã£ãŸ"],
                    horizontal=True
                )
                pleasantness = st.radio(
                    "ãƒ­ãƒœãƒƒãƒˆã¨ã®ä¼šè©±ã¯ã©ã‚Œãã‚‰ã„ã€Œæ„‰å¿«ã•ã€ã‚’æ„Ÿã˜ã¾ã—ãŸã‹ï¼Ÿ",
                    ["éå¸¸ã«æ„‰å¿«ã ã£ãŸ", "ã¾ã‚ã¾ã‚æ„‰å¿«ã ã£ãŸ", "ã©ã¡ã‚‰ã¨ã‚‚ã„ãˆãªã„", "å°‘ã—ä¸æ„‰å¿«ã ã£ãŸ", "ã¨ã¦ã‚‚ä¸æ„‰å¿«ã ã£ãŸ"],
                    horizontal=True
                )
                familiarity = st.radio(
                    "ãƒ­ãƒœãƒƒãƒˆã«ã©ã‚Œãã‚‰ã„ã€Œè¦ªè¿‘æ„Ÿ/è¦ªã—ã¿ã‚„ã™ã•ï¼ˆ=å¿ƒç†çš„è·é›¢æ„Ÿã®è¿‘ã•ï¼‰ã€ã‚’æŒã¡ã¾ã—ãŸã‹ï¼Ÿ",
                    ["å¼·ãæŒã£ãŸ", "ã¾ã‚ã¾ã‚æŒã£ãŸ", "ã©ã¡ã‚‰ã¨ã‚‚ã„ãˆãªã„", "ã‚ã¾ã‚ŠæŒã£ã¦ãªã„", "å…¨ãæŒã£ã¦ã„ãªã„"],
                    horizontal=True
                )
                social_presence = st.radio(
                    "å¯¾è©±ã®ç›¸æ‰‹ãŒãã“ã«å­˜åœ¨ã—ã€è‡ªåˆ†ã¨åŒã˜ç©ºé–“ã‚’å…±æœ‰ã—ã¦ã„ã‚‹ã€ã‚ã‚‹ã„ã¯è‡ªåˆ†ã¨é–¢ã‚ã£ã¦ã„ã‚‹æ„Ÿè¦šã€Œã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ—ãƒ¬ã‚¼ãƒ³ã‚¹ï¼ˆ=å­˜åœ¨æ„Ÿï¼‰ã€ã‚’ã©ã‚Œãã‚‰ã„æŒã¡ã¾ã—ãŸã‹ï¼Ÿ",
                    ["å¼·ãæŒã£ãŸ", "ã¾ã‚ã¾ã‚æŒã£ãŸ", "ã©ã¡ã‚‰ã¨ã‚‚ã„ãˆãªã„", "ã‚ã¾ã‚ŠæŒã£ã¦ãªã„", "å…¨ãæŒã£ã¦ã„ãªã„"],
                    horizontal=True
                )
                security = st.radio(
                    "ãƒ­ãƒœãƒƒãƒˆã«å¯¾ã—ã¦ã©ã‚Œãã‚‰ã„ã€Œå®‰å¿ƒæ„Ÿ/ä¿¡é ¼æ„Ÿã€ã‚’æŒã¡ã¾ã—ãŸã‹ï¼Ÿ",
                    ["å¼·ãæŒã£ãŸ", "ã¾ã‚ã¾ã‚æŒã£ãŸ", "ã©ã¡ã‚‰ã¨ã‚‚ã„ãˆãªã„", "ã‚ã¾ã‚ŠæŒã£ã¦ãªã„", "å…¨ãæŒã£ã¦ã„ãªã„"],
                    horizontal=True
                )
                impression = st.text_input(
                    "AIã¨ã®ä¼šè©±ã‚„ã€ãƒ­ãƒœãƒƒãƒˆã®è¡Œå‹•è¨ˆç”»ã«ã¤ã„ã¦ã€Œå°è±¡ã«æ®‹ã£ãŸã“ã¨ã€ãŒã‚ã‚Œã°ãŠé¡˜ã„ã—ã¾ã™ã€‚"
                )
                free = st.text_input(
                    "ãã®ä»–ã«ä½•ã‹æ„Ÿã˜ãŸã“ã¨ãŒã‚ã‚Œã°ãŠé¡˜ã„ã—ã¾ã™ã€‚"
                )
                submitted = st.form_submit_button("è©•ä¾¡ã‚’ä¿å­˜")

            if submitted:
                st.warning("è©•ä¾¡ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼é©å®œä¼‘æ†©ã‚’ã¨ã£ã¦ãã ã•ã„â˜•")
                scores = {
                    "name": name,
                    "success": success,
                    "failure_reason": failure_reason,
                    "failure_reason_others": failure_reason_others,
                    "grices_maxim": grices_maxim,
                    "kindness": kindness,
                    "pleasantness": pleasantness,
                    "familiarity": familiarity,
                    "social_presence": social_presence,
                    "security": security,
                    "impression": impression,
                    "free": free,
                }
                termination_label = "ä¼šè©±ã‚’å¼·åˆ¶çš„ã«çµ‚äº†" if st.session_state.get("force_end") else ""
                selected_reasons = st.session_state.get("end_reason", [])
                if isinstance(selected_reasons, str):
                    termination_reason = selected_reasons
                else:
                    termination_reason = "ã€".join(selected_reasons)
                save_experiment_1_result(
                    scores,
                    termination_reason,
                    termination_label,
                )
                st.session_state.active = False
                st.session_state["experiment1_followup_prompt"] = True
                st.session_state.pop("experiment1_followup_choice", None)   

    cols = st.columns([1, 1, 2])
    with cols[0]:
        if st.button("âš ï¸ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆ", key="reset_conv"):
            _reset_conversation_state(system_prompt)
            st.rerun()
    with cols[1]:
        if st.button("ğŸš¨ä¼šè©±ã‚’çµ‚äº†", key="force_end_button"):
            st.session_state.force_end = True
            st.session_state.end_reason = st.session_state.get("end_reason", [])
            st.rerun()
    with cols[2]:
        st.multiselect(
            "ä¼šè©±ã‚’çµ‚äº†ã—ãŸã„ç†ç”±",
            [
                "è¡Œå‹•è¨ˆç”»ã¯å®Ÿè¡Œå¯èƒ½ã§ã•ã‚‰ãªã‚‹è³ªå•ã¯ä¸è¦",
                "åŒã˜è³ªå•ãŒç¹°ã‚Šè¿”ã•ã‚Œã‚‹",
                "è¨ˆç”»ãŒç¢ºå®šã—ã¦ã„ã‚‹",
                "LLMã‹ã‚‰è³ªå•ã•ã‚Œãªã„",
                "ãã®ä»–",
            ],
            key="end_reason",
        )
    if st.session_state.get("experiment1_followup_prompt"):
        st.markdown("**GPTãƒ¢ãƒ¼ãƒ‰** ã¨ **GPT with Criticãƒ¢ãƒ¼ãƒ‰** ã§1å›ãšã¤å®Ÿé¨“ã‚’çµ‚ãˆã¾ã—ãŸã‹ï¼Ÿ")
        if st.button("ğŸ™…â€â™‚ï¸ã„ã„ãˆ â†’ â‘ ã®ãƒ¢ãƒ¼ãƒ‰ã‚’å¤‰ãˆã¦å†åº¦å®Ÿé¨“", key="followup_no", type="primary"):
            st.session_state["experiment1_followup_prompt"] = False
            st.session_state.pop("experiment1_followup_choice", None)
            _reset_conversation_state(system_prompt)
            st.rerun()
        if st.button("ğŸ™†â€â™‚ï¸ã¯ã„ â†’ å®Ÿé¨“2", key="followup_yes", type="primary"):
            st.session_state["experiment1_followup_prompt"] = False
            st.session_state.pop("experiment1_followup_choice", None)
            st.session_state.pop(SCROLL_RESET_FLAG_KEY, None)
            st.session_state.pop("experiment2_scroll_reset_done", None)
            st.switch_page("pages/experiment_2.py")

app()
