import json
import random
import re
from pathlib import Path

import streamlit as st
import streamlit.components.v1 as components
import yaml
from consent import (
    apply_sidebar_hiding,
    configure_page,
    require_consent,
    should_hide_sidebar,
)
from dotenv import load_dotenv

from api import build_bootstrap_user_message, client
from jsonl import (
    save_conversation_history_to_firestore,
    save_experiment_2_result,
)
from move_functions import move_to, pick_object, place_object_next_to, place_object_on
from run_and_show import run_plan_and_show, show_spoken_response, show_function_sequence
from image_task_sets import (
    build_task_set_choices,
    extract_task_lines,
    load_image_task_sets,
    resolve_image_paths,
)
from two_classify import prepare_data  # æ—¢å­˜é–¢æ•°ã‚’åˆ©ç”¨
from esm import ExternalStateManager

PROMPT_GROUP = "smalltalk"
NEXT_PAGE = None

PROMPT_TASKINFO_PATH = Path(__file__).resolve().parent.parent / "json" / "prompt_taskinfo_sets.yaml"
_PROMPT_TASKINFO_CACHE: dict[str, dict[str, str]] | None = None


def load_prompt_taskinfo_sets() -> dict[str, dict[str, str]]:
    global _PROMPT_TASKINFO_CACHE
    if _PROMPT_TASKINFO_CACHE is None:
        with PROMPT_TASKINFO_PATH.open(encoding="utf-8") as f:
            _PROMPT_TASKINFO_CACHE = yaml.safe_load(f)
    return _PROMPT_TASKINFO_CACHE


def get_prompt_options(prompt_group: str) -> dict[str, dict[str, str]]:
    return {
        key: value
        for key, value in load_prompt_taskinfo_sets().items()
        if value.get("prompt_group") == prompt_group
    }

SUS_OPTIONS = [
    ("ã¨ã¦ã‚‚å½“ã¦ã¯ã¾ã‚‹ (5)", 5),
    ("ã‚„ã‚„å½“ã¦ã¯ã¾ã‚‹ (4)", 4),
    ("ã©ã¡ã‚‰ã§ã‚‚ãªã„ (3)", 3),
    ("ã‚ã¾ã‚Šå½“ã¦ã¯ã¾ã‚‰ãªã„ (2)", 2),
    ("ã¾ã£ãŸãå½“ã¦ã¯ã¾ã‚‰ãªã„ (1)", 1),
]

SUS_QUESTIONS = [
    ("sus_q1", "ã“ã®ãƒ­ãƒœãƒƒãƒˆã‚’é »ç¹ã«ä½¿ç”¨ã—ãŸã„"),
    ("sus_q2", "ã“ã®ãƒ­ãƒœãƒƒãƒˆã¯å¿…è¦ä»¥ä¸Šã«è¤‡é›‘ã ã¨æ€ã†"),
    ("sus_q3", "ã“ã®ãƒ­ãƒœãƒƒãƒˆã¯ä½¿ã„ã‚„ã™ã„ã¨æ„Ÿã˜ãŸ"),
    ("sus_q4", "ã“ã®ãƒ­ãƒœãƒƒãƒˆã‚’ä½¿ã†ã«ã¯å°‚é–€çš„ãªã‚µãƒãƒ¼ãƒˆãŒå¿…è¦ã "),
    ("sus_q5", "ã“ã®ãƒ­ãƒœãƒƒãƒˆã®æ§˜ã€…ãªæ©Ÿèƒ½ã¯çµ±åˆã•ã‚Œã¦ã„ã‚‹ã¨æ„Ÿã˜ãŸ"),
    ("sus_q6", "ã“ã®ãƒ­ãƒœãƒƒãƒˆã¯ä¸€è²«æ€§ãŒæ¬ ã‘ã¦ã„ã‚‹ã¨æ€ã†"),
    ("sus_q7", "å¤§åŠã®äººã¯ã“ã®ãƒ­ãƒœãƒƒãƒˆã‚’ã™ãã«ä½¿ã„ã“ãªã›ã‚‹ã‚ˆã†ã«ãªã‚‹ã¨æ€ã†"),
    ("sus_q8", "ã“ã®ãƒ­ãƒœãƒƒãƒˆã¯æ“ä½œã—ã«ãã„"),
    ("sus_q9", "ã“ã®ãƒ­ãƒœãƒƒãƒˆã‚’ä½¿ã„ã“ãªã›ã‚‹è‡ªä¿¡ãŒã‚ã‚‹"),
    ("sus_q10", "ã“ã®ãƒ­ãƒœãƒƒãƒˆã‚’ä½¿ã„å§‹ã‚ã‚‹å‰ã«çŸ¥ã‚‰ãªã‘ã‚Œã°ãªã‚‰ãªã„ã“ã¨ãŒãŸãã•ã‚“ã‚ã‚‹ã¨æ€ã†"),
]

NASA_TLX_QUESTIONS = [
    ("nasa_mental_demand", "ã‚ãªãŸã¯ã€ãƒ­ãƒœãƒƒãƒˆã¨ä¼šè©±ã‚’ã™ã‚‹ã«ã‚ãŸã£ã¦ã€ç²¾ç¥çš„è¦æ±‚ï¼ˆæ€è€ƒï¼Œæ„å¿—æ±ºå®šï¼Œè¨ˆç®—ï¼Œè¨˜æ†¶ï¼Œè¦³å¯Ÿï¼Œæ¤œç´¢ï¼Œç­‰ï¼‰ãŒã©ã‚Œãã‚‰ã„è¦æ±‚ã•ã‚Œã¾ã—ãŸã‹ï¼Ÿ"),
    ("nasa_physical_demand", "ã‚ãªãŸã¯ã€ãƒ­ãƒœãƒƒãƒˆã¨ä¼šè©±ã‚’ã™ã‚‹ã«ã‚ãŸã£ã¦ã€èº«ä½“çš„è¦æ±‚ï¼ˆæŠ¼ã™ï¼Œå¼•ãï¼Œå›ã™ï¼Œ æ“ä½œã™ã‚‹ç­‰ï¼‰ãŒã©ã‚Œãã‚‰ã„è¦æ±‚ã•ã‚Œã¾ã—ãŸã‹ï¼Ÿ"),
    ("nasa_temporal_demand", "ã‚ãªãŸã¯ã€ãƒ­ãƒœãƒƒãƒˆã¨ä¼šè©±ã‚’ã™ã‚‹ã«ã‚ãŸã£ã¦ã€æ™‚é–“çš„åˆ‡è¿«æ„Ÿï¼ˆä½œæ¥­ã‚„è¦ç´ ä½œæ¥­ã®é »åº¦ã‚„é€Ÿã•ï¼‰ã‚’ã©ã®ç¨‹åº¦æ„Ÿã˜ã¾ã—ãŸã‹ï¼Ÿ"),
    ("nasa_performance", "ãƒ­ãƒœãƒƒãƒˆã¨ä¼šè©±ã‚’ã™ã‚‹ã«ã‚ãŸã£ã¦ã€ã‚ãªãŸè‡ªèº«ãŒè¨­å®šã—ãŸä½œæ¥­ï¼ˆæŒ‡ç¤ºï¼‰ã¯ã€ã©ã®ç¨‹åº¦ãƒ­ãƒœãƒƒãƒˆã«ã‚ˆã£ã¦é”æˆã•ã‚ŒãŸã¨è€ƒãˆã¾ã™ã‹ï¼Ÿ"),
    ("nasa_effort", "ã‚ãªãŸã¯ãã®ä½œæ¥­é”æˆç‡ã«åˆ°é”ã™ã‚‹ã®ã«ã€ã©ã®ãã‚‰ã„ï¼ˆç²¾ç¥çš„ãŠã‚ˆã³èº«ä½“çš„ã«ï¼‰åŠªåŠ›ã—ã¾ã—ãŸã‹ï¼Ÿ"),
    ("nasa_frustration", "ã‚ãªãŸã¯ã€ãƒ­ãƒœãƒƒãƒˆã¨ä¼šè©±ã‚’ã™ã‚‹ã«ã‚ãŸã£ã¦ã©ã®ãã‚‰ã„ä¸å®‰ï¼Œè½èƒ†ï¼Œã„ã‚‰ã„ã‚‰ï¼Œã‚¹ãƒˆãƒ¬ã‚¹ï¼Œä¸å¿«æ„Ÿã‚’æ„Ÿã˜ã¾ã—ãŸã‹ï¼Ÿ"),
]


GodSpeed_anthroporphism_QUESTIONS = [
    ("godspeed_anthroporphism1", "Fake å½ç‰©ã®ã‚ˆã†ãª (1) - Natural è‡ªç„¶ãª (5)"),
    ("godspeed_anthroporphism2", "Machinelike æ©Ÿæ¢°çš„ (1) - Humanlike äººé–“çš„ (5)"),
    ("godspeed_anthroporphism3", "Unconscious æ„è­˜ã‚’æŒãŸãªã„ (1) - Contious æ„è­˜ã‚’æŒã£ã¦ã„ã‚‹ (5)"),
    ("godspeed_anthroporphism4", "Artificial äººå·¥çš„ (1) - Lifelike ç”Ÿç‰©çš„ (5)"),
    ("godspeed_anthroporphism5", "Moving rigidly ãã“ã¡ãªã„å‹•ã (1) - Moving elegantly æ´—ç·´ã•ã‚ŒãŸå‹•ã (1)")
]

GodSpeed_animacy_QUESTIONS = [
    ("godspeed_animacy1", "Dead æ­»ã‚“ã§ã„ã‚‹ (1) - Alive ç”Ÿãã¦ã„ã‚‹ (5)"),
    ("godspeed_animacy2", "Stagnant æ´»æ°—ã®ãªã„ (1) - Lively ç”Ÿãç”Ÿãã¨ã—ãŸ (5)"),
    ("godspeed_animacy3", "Mechanical æ©Ÿæ¢°çš„ãª (1) - Organic æœ‰æ©Ÿçš„ãª (5)"),
    ("godspeed_animacy4", "Inert ä¸æ´»ç™ºãª (1) - Interactive å¯¾è©±çš„ãª (5)"),
    ("godspeed_animacy5", "Apathetic ç„¡é–¢å¿ƒãª (1) - Responsive åå¿œã®ã‚ã‚‹ (5)")
]

GodSpeed_likebility_QUESTIONS = [
    ("godspeed_likeability1", "Dislike å«Œã„ (1) - Like å¥½ã (5)"),
    ("godspeed_likeability2", "Unfriendly è¦ªã—ã¿ã«ãã„ (1) - Friendly è¦ªã—ã¿ã‚„ã™ã„ (5)"),
    ("godspeed_likeability3", "Unkind ä¸è¦ªåˆ‡ãª (1) - Kind è¦ªåˆ‡ãª (5)"),
    ("godspeed_likeability4", "Unpleasant ä¸æ„‰å¿«ãª (1) - Pleasant æ„‰å¿«ãª (5)"),
    ("godspeed_likeability5", "Awful ã²ã©ã„ (1) - Nice è‰¯ã„ (5)")
]

GodSpeed_perceived_intelligence_QUESTIONS = [
    ("godspeed_intelligence1", "Incompetent ç„¡èƒ½ãª (1) - Competent æœ‰èƒ½ãª (5)"),
    ("godspeed_intelligence2", "Ignorant ç„¡çŸ¥ãª (1) - Knowledgeable ç‰©çŸ¥ã‚Šãª (5)"),
    ("godspeed_intelligence3", "Irresponsible ç„¡è²¬ä»»ãª (1) - Responsible è²¬ä»»ã®ã‚ã‚‹ (5)"),
    ("godspeed_intelligence4", "Unintelligent çŸ¥çš„ã§ãªã„ (1) - Intelligent çŸ¥çš„ãª (5)"),
    ("godspeed_intelligence5", "Foolish æ„šã‹ãª (1) - Sensible è³¢æ˜ãª (5)")
]

GodSpeed_perceived_safety_QUESTIONS = [
    ("godspeed_safety1", "Anxious ä¸å®‰ãª (1) - Relaxed è½ã¡ç€ã„ãŸ (5)"),
    ("godspeed_safety2", "Agitated å‹•æºã—ã¦ã„ã‚‹ (1) - Calm å†·é™ãª (5)"),
    ("godspeed_safety3", "Quiescent å¹³ç©ãª (1) - Surprised é©šã„ãŸ (5)")
]

load_dotenv()


configure_page(hide_sidebar_for_participant=True)


def _reset_conversation_state(system_prompt: str) -> None:
    """Reset conversation-related session state for experiment 2."""

    # 1. ESMï¼ˆçŠ¶æ…‹ï¼‰ã®åˆæœŸåŒ–
    st.session_state.esm = ExternalStateManager() 
    
    # 2. å®Ÿè¡Œã™ã¹ãè¡Œå‹•è¨ˆç”»ã®ã‚­ãƒ¥ãƒ¼ï¼ˆåå‰ã‚’ action_plan_queue ã«çµ±ä¸€ï¼‰
    st.session_state.action_plan_queue = [] 
    
    # 3. ãƒ•ã‚§ãƒ¼ã‚º1ï¼ˆç›®æ¨™è¨­å®šï¼‰ãŒå®Œäº†ã—ãŸã‹ã®ãƒ•ãƒ©ã‚°
    st.session_state.goal_set = False 
    
    # 4. ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã€Œãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã€ã¨ã—ã¦ä¿æŒ
    #    (LLMå‘¼ã³å‡ºã—ã®åº¦ã« {current_state_xml} ã‚’åŸ‹ã‚è¾¼ã‚€ãŸã‚)
    st.session_state.system_prompt_template = system_prompt 
    
    # 5. contextã¯ã€Œç©ºã€ã§é–‹å§‹ã™ã‚‹
    st.session_state.context = [] 
    
    # --- ä»¥ä¸‹ã¯æ—¢å­˜ã®ãƒªã‚»ãƒƒãƒˆãƒ­ã‚¸ãƒƒã‚¯ ---
    st.session_state.active = True
    st.session_state.conv_log = {
        "label": "",
        "clarifying_steps": []
    }
    st.session_state.saved_jsonl = []
    st.session_state.turn_count = 0
    st.session_state.force_end = False
    st.session_state["chat_input_history"] = []
    st.session_state["experiment2_followup_prompt"] = False
    st.session_state.pop("experiment2_followup_choice", None)
    _update_random_task_selection(
        "experiment2_selected_task_label",
        "experiment2_task_labels",
        "experiment2_label_to_key",
        "experiment2_selected_task_set",
    )

def _update_random_task_selection(label_key: str, labels_key: str, mapping_key: str, set_key: str) -> None:
    """Select a new task label at random and update related session state."""

    labels = st.session_state.get(labels_key) or []
    if not labels:
        return

    current_label = st.session_state.get(label_key)
    candidates = [label for label in labels if label != current_label] or labels
    new_label = random.choice(candidates)

    st.session_state[label_key] = new_label
    label_to_key = st.session_state.get(mapping_key) or {}
    st.session_state[set_key] = label_to_key.get(new_label)

TAG_RE = re.compile(r"</?([A-Za-z0-9_]+)(\s[^>]*)?>")

def strip_tags(text: str) -> str:
    return TAG_RE.sub("", text or "").strip()

def extract_between(tag: str, text: str) -> str | None:
    match = re.search(fr"<{tag}>([\s\S]*?)</{tag}>", text or "", re.IGNORECASE)
    return match.group(1).strip() if match else None

def extract_xml_tag(xml_string, tag_name):
    """æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚°ã®å†…å®¹ã‚’æŠ½å‡ºã™ã‚‹"""
    pattern = f"<{tag_name}>(.*?)</{tag_name}>"
    match = re.search(pattern, xml_string, re.DOTALL | re.IGNORECASE)
    return match.group(1).strip() if match else None

def parse_function_sequence(sequence_str):
    """FunctionSequenceã®ç•ªå·ä»˜ããƒªã‚¹ãƒˆã‚’ãƒ‘ãƒ¼ã‚¹ã™ã‚‹"""
    if not sequence_str:
        return []
    # "1. go to..." "2. pick up..." ãªã©ã‚’æŠ½å‡º
    actions = re.findall(r'^\s*\d+\.\s*(.*)', sequence_str, re.MULTILINE)
    return [action.strip() for action in actions]

def safe_format_prompt(template: str, **kwargs) -> str:
    # {current_state_xml},{house},{room} ã ã‘ã‚’ç½®æ›ã—ã€ä»–ã® { ... } ã¯è§¦ã‚‰ãªã„
    pattern = re.compile(r"\{(current_state_xml|house|room)\}")
    return pattern.sub(lambda m: str(kwargs.get(m.group(1), m.group(0))), template)

def run_plan_and_show(reply: str):
    """<Plan> ... </Plan> ã‚’è¦‹ã¤ã‘ã¦å®Ÿè¡Œã—ã€çµæœã‚’è¡¨ç¤º"""
    plan_match = re.search(r"<Plan>(.*?)</Plan>", reply, re.S)
    if not plan_match:
        return
    steps = re.findall(r"<Step>(.*?)</Step>", plan_match.group(1))
    if not steps:
        return

    with st.expander("Plan å®Ÿè¡Œãƒ­ã‚°", expanded=True):
        for step in steps:
            try:
                result = eval(step)  # ä¾‹: move_to(1.0, 2.0)
                st.write(f"âœ… `{step}` â†’ **{result}**")
            except Exception as e:
                st.write(f"âš ï¸ `{step}` ã®å®Ÿè¡Œã§ã‚¨ãƒ©ãƒ¼: {e}")

def finalize_and_render_plan(label: str):
    """ä¼šè©±çµ‚äº†æ™‚ã«è¡Œå‹•è¨ˆç”»ã‚’ã¾ã¨ã‚ã¦ç”»é¢è¡¨ç¤º"""
    # final_answer ã®æ±ºå®š
    last_assistant = next((m for m in reversed(st.session_state.context) if m["role"] == "assistant"), None)
    final_answer = extract_between("FinalAnswer", last_assistant["content"]) if last_assistant else None
    if not final_answer and last_assistant:
        final_answer = strip_tags(last_assistant["content"])

    st.session_state.conv_log["final_answer"] = final_answer or ""
    st.session_state.conv_log["label"] = "sufficient" if label == "sufficient" else "insufficient"

    # question_label ãŒ None ã®ã‚¹ãƒ†ãƒƒãƒ—ã¯ç¶™ç¶šãŒç„¡ã‘ã‚Œã° insufficient ã§åŸ‹ã‚ã‚‹
    for s in st.session_state.conv_log["clarifying_steps"]:
        if s["question_label"] is None:
            s["question_label"] = "insufficient"

    st.subheader("ä¼šè©±ã‚µãƒãƒªï¼ˆJSONï¼‰")
    st.code(
        json.dumps(st.session_state.conv_log, ensure_ascii=False, indent=2),
        language="json"
    )

def _build_text_for_model(instruction: str, function_sequence: str, information: str) -> str:
    # å­¦ç¿’æ™‚(two_classify.py)ã® prepare_data ã¨åŒã˜æ¥é ­è¾ãƒ»çµåˆé †ã«åˆã‚ã›ã‚‹
    parts = []
    if instruction.strip():
        parts.append(f"Instruction: {instruction.strip()}")
    if function_sequence.strip():
        parts.append(f"FunctionSequence: {function_sequence.strip()}")
    if information.strip():
        parts.append(f"Information: {information.strip()}")
    return " | ".join(parts)

def _extract_between(tag: str, text: str) -> str | None:
    m = re.search(fr"<{tag}>([\s\S]*?)</{tag}>", text or "", re.IGNORECASE)
    return m.group(1).strip() if m else ""

def app():
    # require_consent()
    st.markdown("### å®Ÿé¨“ ç•°ãªã‚‹ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—ã®æ¯”è¼ƒ")

    if should_hide_sidebar():
        apply_sidebar_hiding()

    prompt_options = get_prompt_options(PROMPT_GROUP)
    if not prompt_options:
        st.error("æŒ‡å®šã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚°ãƒ«ãƒ¼ãƒ—ã«å¯¾å¿œã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    prompt_keys = list(prompt_options.keys())
    prompt_label_state_key = f"experiment2_{PROMPT_GROUP}_prompt_label"
    if prompt_label_state_key not in st.session_state:
        st.session_state[prompt_label_state_key] = random.choice(prompt_keys)

    default_prompt_label = st.session_state[prompt_label_state_key]
    st.markdown("#### â‘ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé¸æŠï¼ˆè‡ªå‹•ï¼‰")
    prompt_label = st.selectbox(
        "é¸æŠè‚¢",
        prompt_keys,
        index=prompt_keys.index(default_prompt_label)
        if default_prompt_label in prompt_keys
        else 0,
    )
    selected_prompt = prompt_options[prompt_label]
    system_prompt = selected_prompt.get("prompt", "")
    selected_task_name = selected_prompt.get("task", "")
    selected_taskinfo = selected_prompt.get("taskinfo", "")

    if not system_prompt:
        st.error("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å†…å®¹ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return

    st.session_state[prompt_label_state_key] = prompt_label

    st.write("â€»ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¦ã‚‚ã“ã®é¸æŠã¯å¤‰ã‚ã‚Šã¾ã›ã‚“ã€‚")

    payload = None
    with st.expander("ã‚¿ã‚¹ã‚¯èª¿æ•´ï¼ˆä»»æ„ï¼‰", expanded=False):
        task_sets = load_image_task_sets()
        if not task_sets:
            st.warning("å†™çœŸã¨ã‚¿ã‚¹ã‚¯ã®ã‚»ãƒƒãƒˆãŒä¿å­˜ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã¾ãšã€å†™çœŸã¨ã‚¿ã‚¹ã‚¯ã®é¸å®šãƒ»ä¿å­˜ã€ãƒšãƒ¼ã‚¸ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚")
            st.session_state["selected_image_paths"] = []
            st.session_state["experiment2_selected_task_set"] = None
            st.session_state["experiment2_task_labels"] = []
            st.session_state["experiment2_label_to_key"] = {}
            payload = {}
        else:
            choice_pairs = build_task_set_choices(task_sets)
            labels = [label for label, _ in choice_pairs]
            label_to_key = {label: key for label, key in choice_pairs}

            st.session_state["experiment2_task_labels"] = labels
            st.session_state["experiment2_label_to_key"] = label_to_key

            if not labels:
                st.warning("ä¿å­˜æ¸ˆã¿ã®ã‚¿ã‚¹ã‚¯ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
                st.session_state["selected_image_paths"] = []
                st.session_state["experiment2_selected_task_set"] = None
                st.session_state["experiment2_task_labels"] = []
                st.session_state["experiment2_label_to_key"] = {}
                payload = {}
            else:
                stored_label = st.session_state.get("experiment2_selected_task_label")
                if stored_label not in labels:
                    stored_label = random.choice(labels)
                selected_label = st.selectbox(
                    "ã‚¿ã‚¹ã‚¯",
                    labels,
                    index=labels.index(stored_label),
                )
                st.session_state["experiment2_selected_task_label"] = selected_label
                selected_task_name = label_to_key.get(selected_label)
                st.session_state["experiment2_selected_task_set"] = selected_task_name
                payload = task_sets.get(selected_task_name, {}) if selected_task_name else {}
    if not isinstance(payload, dict):
        payload = {}

    house = payload.get("house") if isinstance(payload, dict) else ""
    room = payload.get("room") if isinstance(payload, dict) else ""
    meta_lines = []

    task_lines = extract_task_lines(payload)

    st.markdown("#### â‘¡æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚¹ã‚¯")
    st.write("ä¸‹ã®ã‚¿ã‚¹ã‚¯ã‚’ãã®ã¾ã¾ç”»é¢ä¸‹éƒ¨ã®ãƒãƒ£ãƒƒãƒˆã«å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    if selected_taskinfo:
        st.info(selected_taskinfo)
    else:
        st.info("ã‚¿ã‚¹ã‚¯ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    # if task_lines:
    #     for line in task_lines:
    #         st.info(f"{line}")
    # else:
    #     st.info("ã‚¿ã‚¹ã‚¯ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    # 1) ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ESMã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆæœŸåŒ–
    if (
        "esm" not in st.session_state
        or st.session_state.get("system_prompt_template") != system_prompt
    ):
        _reset_conversation_state(system_prompt) 

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰ESMã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å–å¾—
    esm = st.session_state.esm
    
    if "active" not in st.session_state:
        st.session_state.active = True
    if "turn_count" not in st.session_state:
        st.session_state.turn_count = 0
    if "force_end" not in st.session_state:
        st.session_state.force_end = False
    if "chat_input_history" not in st.session_state:
        st.session_state["chat_input_history"] = []
    if "experiment2_followup_prompt" not in st.session_state:
        st.session_state["experiment2_followup_prompt"] = False

    context = st.session_state.context
    esm = st.session_state.esm
    queue = st.session_state.action_plan_queue
    current_state = esm.current_state
    should_stop = False
    end_message = ""

    tab_conversation, tab_state = st.tabs([
        "â‘£ãƒ­ãƒœãƒƒãƒˆã¨ã®ä¼šè©±",
        "â‘¢ç¾åœ¨ã®çŠ¶æ…‹",
    ])

    with tab_conversation:
        st.markdown("#### â‘£ãƒ­ãƒœãƒƒãƒˆã¨ã®ä¼šè©±")
        st.write(
            "æœ€åˆã«â‘¡ã®ã‚¿ã‚¹ã‚¯ã‚’å…¥åŠ›ã—ã€ãƒ­ãƒœãƒƒãƒˆã¨è‡ªç”±ã«ä¼šè©±ã—ã¦ãã ã•ã„ã€‚"
            "æœ€çµ‚çš„ã«ã¯ãƒ­ãƒœãƒƒãƒˆã¨ä¸€ç·’ã«ã€ã‚¿ã‚¹ã‚¯ã‚’é”æˆã•ã›ã¦ãã ã•ã„ã€‚"
        )

        # 2. æ—¢å­˜ã®ä¼šè©±å±¥æ­´ã‚’è¡¨ç¤º
        for msg in context:
            if msg["role"] == "system":
                continue
            with st.chat_message(msg["role"]):
                st.write(msg["content"])
                # æ—¢å­˜ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã‚’ãã®ã¾ã¾åˆ©ç”¨
                if msg["role"] == "assistant":
                    reply_xml = msg.get("full_reply", msg.get("content", ""))
                    show_function_sequence(reply_xml)
                    # show_spoken_response(reply_xml)

        # 3. [ãƒ•ã‚§ãƒ¼ã‚º2: å®Ÿè¡Œãƒ«ãƒ¼ãƒ—] å®Ÿè¡Œã™ã¹ãè¡Œå‹•è¨ˆç”»ï¼ˆã‚­ãƒ¥ãƒ¼ï¼‰ãŒã‚ã‚‹ã‹ï¼Ÿ
        if queue:
            next_action = queue[0]
            st.info(f"æ¬¡ã®è¡Œå‹•è¨ˆç”»: **{next_action}**")

            # å®Ÿè¡Œãƒœã‚¿ãƒ³
            if st.button(f"â–¶ï¸ å®Ÿè¡Œ: {next_action}", key="run_next_step", type="primary"):
                action_to_run = queue.pop(0)  # ã‚­ãƒ¥ãƒ¼ã®å…ˆé ­ã‚’å–ã‚Šå‡ºã™
                st.session_state.action_plan_queue = queue  # ã‚­ãƒ¥ãƒ¼ã‚’æ›´æ–°

                # [!!!] ã“ã“ã§å®Ÿéš›ã®ãƒ­ãƒœãƒƒãƒˆAPIã‚’å‘¼ã³å‡ºã™ï¼ˆä»£ã‚ã‚Šã«ESMã‚’æ›´æ–°ï¼‰[!!!]
                with st.spinner(f"å®Ÿè¡Œä¸­: {action_to_run}..."):
                    # time.sleep(1) # import time ãŒå¿…è¦
                    esm.update_state_from_action(action_to_run)

                # å®Ÿè¡Œçµæœã‚’ä¼šè©±å±¥æ­´ï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼‰ã«è¿½åŠ 
                exec_msg = (
                    f"ï¼ˆå®Ÿè¡Œå®Œäº†: {action_to_run}ã€‚ãƒ­ãƒœãƒƒãƒˆã®çŠ¶æ…‹ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚ï¼‰"
                )
                context.append({"role": "user", "content": exec_msg})  # å®Ÿè¡Œçµæœã‚’LLMã«ä¼ãˆã‚‹
                st.chat_message("user").write(exec_msg)

                # ã‚­ãƒ¥ãƒ¼ãŒç©ºã«ãªã£ãŸã‚‰ã€LLMã«æ¬¡ã®è¨ˆç”»ã‚’å°‹ã­ã‚‹
                if not queue:
                    st.info("ã‚µãƒ–ã‚¿ã‚¹ã‚¯ãŒå®Œäº†ã—ã¾ã—ãŸã€‚LLMã«æ¬¡ã®è¨ˆç”»ã‚’å•ã„åˆã‚ã›ã¾ã™...")
                    context.append(
                        {
                            "role": "user",
                            "content": "ã“ã®ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã¯å®Œäº†ã—ã¾ã—ãŸã€‚ç¾åœ¨ã®çŠ¶æ…‹ã«åŸºã¥ãã€æ¬¡ã®ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã‚’è¨ˆç”»ã—ã¦ãã ã•ã„ã€‚",
                        }
                    )
                    st.session_state.trigger_llm_call = True

                st.rerun()  # ç”»é¢ã‚’å†æç”»ã—ã¦æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¡¨ç¤º

        # 4. LLMå‘¼ã³å‡ºã—ã®ãƒˆãƒªã‚¬ãƒ¼ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ› or è¨ˆç”»å®Œäº†ï¼‰
        user_input = None
        if not st.session_state.get("force_end"):
            user_input = st.chat_input(
                "ãƒ­ãƒœãƒƒãƒˆã¸ã®å›ç­”ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
                key="experiment_2_chat_input",
            )
            if user_input:
                st.session_state["chat_input_history"].append(user_input)
                st.session_state.trigger_llm_call = True

                # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå…¥åŠ›ã—ãŸ=æ—¢å­˜ã®è¨ˆç”»ã«ä»‹å…¥ã—ãŸâ†’ã—ãŸãŒã£ã¦å¤ã„è¡Œå‹•è¨ˆç”»ï¼ˆã‚­ãƒ¥ãƒ¼ï¼‰ã‚’ç ´æ£„ã™ã‚‹
                if queue:
                    st.warning("ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä»‹å…¥ã—ã¾ã—ãŸã€‚æ—¢å­˜ã®è¡Œå‹•è¨ˆç”»ã‚’ç ´æ£„ã—ã¾ã™ã€‚")
                    st.session_state.action_plan_queue = []
                    queue = []

        # 5. [ãƒ•ã‚§ãƒ¼ã‚º1 & 2: LLMå‘¼ã³å‡ºã—]
        if st.session_state.get("trigger_llm_call"):
            st.session_state.trigger_llm_call = False  # ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ

            # [å¤‰æ›´ç‚¹] ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãŒã‚ã£ãŸå ´åˆã®ã¿ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«è¿½åŠ 
            if user_input:
                context.append({"role": "user", "content": user_input})

            # [!!!] LLMå‘¼ã³å‡ºã—ã®ã‚³ã‚¢ãƒ­ã‚¸ãƒƒã‚¯ [!!!]
            with st.chat_message("assistant"):
                with st.spinner("ãƒ­ãƒœãƒƒãƒˆãŒè€ƒãˆã¦ã„ã¾ã™..."):
                    # (A) ESMã‹ã‚‰æœ€æ–°ã®çŠ¶æ…‹XMLã‚’å–å¾—
                    current_state_xml = esm.get_state_as_xml_prompt()
                    # (B) æœ€æ–°ã®çŠ¶æ…‹ã§ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
                    house = (payload.get("house") if isinstance(payload, dict) else "") or ""
                    room = (payload.get("room") if isinstance(payload, dict) else "") or ""
                    system_prompt_content = safe_format_prompt(
                        st.session_state.system_prompt_template,
                        current_state_xml=current_state_xml,
                        house=house,
                        room=room,
                    )
                    system_message = {"role": "system", "content": system_prompt_content}

                    # (C) APIã«æ¸¡ã™ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã‚’ä½œæˆ
                    messages_for_api = [system_message] + context

                    # (D) LLM API å‘¼ã³å‡ºã—
                    response = client.chat.completions.create(
                        model="gpt-4o-mini",  # ã¾ãŸã¯ "gpt-4-turbo"
                        messages=messages_for_api,
                    )
                    reply = response.choices[0].message.content.strip()

                    # (E) å¿œç­”ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«è¿½åŠ 
                    spoken_response = extract_xml_tag(reply, "SpokenResponse")
                    if not spoken_response:
                        spoken_response = strip_tags(reply) or "(...)"

                    context.append(
                        {
                            "role": "assistant",
                            "content": spoken_response,
                            "full_reply": reply,
                        }
                    )
                    st.session_state.turn_count += 1

                    # (F) [ãƒ•ã‚§ãƒ¼ã‚º1] GoalãŒè¨­å®šã•ã‚ŒãŸã‹ãƒ‘ãƒ¼ã‚¹
                    goal_def_str = extract_xml_tag(reply, "TaskGoalDefinition")
                    if (
                        goal_def_str
                        and "Goal:" in goal_def_str
                        and not st.session_state.goal_set
                    ):
                        if esm.set_task_goal_from_llm(goal_def_str):
                            st.session_state.goal_set = True
                            st.success("ã‚¿ã‚¹ã‚¯ç›®æ¨™ã‚’è¨­å®šã—ã¾ã—ãŸï¼")
                        else:
                            st.error("LLMãŒç”Ÿæˆã—ãŸã‚¿ã‚¹ã‚¯ç›®æ¨™ã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

                    # (G) [ãƒ•ã‚§ãƒ¼ã‚º2] è¡Œå‹•è¨ˆç”»ãŒç”Ÿæˆã•ã‚ŒãŸã‹ãƒ‘ãƒ¼ã‚¹
                    plan_str = extract_xml_tag(reply, "FunctionSequence")
                    if plan_str:
                        # [å¤‰æ›´ç‚¹] ä»‹å…¥æ™‚ã«å¤ã„è¨ˆç”»ãŒã‚¯ãƒªã‚¢ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€extendã§OK
                        actions = parse_function_sequence(plan_str)
                        if actions:
                            st.session_state.action_plan_queue.extend(actions)
                            st.info(f"{len(actions)}ã‚¹ãƒ†ãƒƒãƒ—ã®è¨ˆç”»ã‚’å—ä¿¡ã—ã¾ã—ãŸã€‚")

                    # (H) ç”»é¢ã‚’å†æç”»
                    st.rerun()

    if st.session_state.get("force_end"):
        should_stop = True
        end_message = "ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä¼šè©±ã‚’çµ‚äº†ã—ã¾ã—ãŸã€‚"

    with tab_state:
        st.markdown("#### â‘¢ç¾åœ¨ã®çŠ¶æ…‹")
        st.caption(
            "ExternalStateManager (ESM) ãŒä¿æŒã—ã¦ã„ã‚‹çŠ¶æ…‹ã§ã™ã€‚ãƒ­ãƒœãƒƒãƒˆã®è¡Œå‹•ã«å¿œã˜ã¦æ›´æ–°ã•ã‚Œã¾ã™ã€‚"
        )

        # --- 1. ãƒ­ãƒœãƒƒãƒˆã®çŠ¶æ…‹ ---
        st.markdown("##### ğŸ¤– ãƒ­ãƒœãƒƒãƒˆ")
        col1, col2 = st.columns(2)

        # esm.py ã®ã‚­ãƒ¼ã«åˆã‚ã›ã¦æŒ‡å®š
        robot_stat = current_state.get("robot_status", {})
        location = robot_stat.get("location", "ä¸æ˜")
        holding = robot_stat.get("holding", "ãªã—")

        # 'living_room' -> 'Living Room' ã®ã‚ˆã†ã«æ•´å½¢ã—ã¦è¡¨ç¤º
        col1.metric("ç¾åœ¨åœ°", location.replace("_", " ").title())
        col2.metric("æ´ã‚“ã§ã„ã‚‹ç‰©", str(holding) if holding else "ãªã—")

        st.divider()  # åŒºåˆ‡ã‚Šç·š

        # --- 2. ç’°å¢ƒã®çŠ¶æ…‹ ---
        st.markdown("##### ğŸ  ç’°å¢ƒï¼ˆå ´æ‰€ã”ã¨ã®ã‚¢ã‚¤ãƒ†ãƒ ï¼‰")
        environment_state = current_state.get("environment", {})

        # å ´æ‰€ãŒå¤šã„ãŸã‚2åˆ—ã«åˆ†ã‘ã¦è¡¨ç¤º
        env_cols = st.columns(2)

        # è¾æ›¸ã®ã‚­ãƒ¼ï¼ˆå ´æ‰€ï¼‰ã‚’åŠåˆ†ã«åˆ†ã‘ã‚‹
        locations = list(environment_state.keys())
        mid_point = (len(locations) + 1) // 2
        locations_col1 = locations[:mid_point]
        locations_col2 = locations[mid_point:]

        # å·¦å´ã®åˆ—
        with env_cols[0]:
            for loc in locations_col1:
                items = environment_state.get(loc, [])
                # 'kitchen_shelf' -> 'Kitchen Shelf'
                loc_label = loc.replace("_", " ").title()

                with st.expander(f"{loc_label} ({len(items)}å€‹)"):
                    if items:
                        st.multiselect(
                            f"ï¼ˆ{loc_label}ã«ã‚ã‚‹ç‰©ï¼‰",
                            items,
                            default=items,
                            disabled=True,
                            label_visibility="collapsed",  # ãƒ©ãƒ™ãƒ«ã‚’éè¡¨ç¤ºã«
                        )
                    else:
                        st.info("ï¼ˆä½•ã‚‚ã‚ã‚Šã¾ã›ã‚“ï¼‰")

        # å³å´ã®åˆ—
        with env_cols[1]:
            for loc in locations_col2:
                items = environment_state.get(loc, [])
                loc_label = loc.replace("_", " ").title()

                with st.expander(f"{loc_label} ({len(items)}å€‹)"):
                    if items:
                        st.multiselect(
                            f"ï¼ˆ{loc_label}ã«ã‚ã‚‹ç‰©ï¼‰",
                            items,
                            default=items,
                            disabled=True,
                            label_visibility="collapsed",
                        )
                    else:
                        st.info("ï¼ˆä½•ã‚‚ã‚ã‚Šã¾ã›ã‚“ï¼‰")

        # --- 3. ã‚¿ã‚¹ã‚¯ç›®æ¨™ (ã¤ã„ã§ã«è¡¨ç¤º) ---
        st.divider()
        st.markdown("##### ğŸ¯ ç¾åœ¨ã®ã‚¿ã‚¹ã‚¯ç›®æ¨™")
        task_goal = current_state.get("task_goal", {})
        target_loc = task_goal.get("target_location", "æœªè¨­å®š")
        items_needed = task_goal.get("items_needed", {})

        col_t1, col_t2 = st.columns(2)
        col_t1.metric("ç›®æ¨™åœ°ç‚¹", str(target_loc).title() if target_loc else "æœªè¨­å®š")

        if items_needed:
            # è¾æ›¸ { 'itemA': 2, 'itemB': 1 } ã‚’ãƒªã‚¹ãƒˆè¡¨ç¤º
            item_list = [f"{item} (x{count})" for item, count in items_needed.items()]
            col_t2.markdown("**å¿…è¦ãªã‚¢ã‚¤ãƒ†ãƒ :**")
            col_t2.dataframe(
                item_list,
                use_container_width=True,
                hide_index=True,
                column_config={"value": "ã‚¢ã‚¤ãƒ†ãƒ  (å€‹æ•°)"},
            )
        else:
            col_t2.metric("å¿…è¦ãªã‚¢ã‚¤ãƒ†ãƒ ", "ãªã—")

        # --- å…ƒã®JSONã¯ãƒ‡ãƒãƒƒã‚°ç”¨ã«æŠ˜ã‚ŠãŸãŸã‚“ã§æ®‹ã™ ---
        with st.expander("è©³ç´°ãªçŠ¶æ…‹ï¼ˆJSONï¼‰"):
            st.json(current_state)

    # 7. è©•ä¾¡ãƒ•ã‚©ãƒ¼ãƒ ã®è¡¨ç¤ºï¼ˆshould_stopåˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ã¯å¤‰æ›´æ¸ˆã¿ï¼‰  
    end_message = ""
    if st.session_state.get("force_end"):
        should_stop = True
        end_message = "ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä¼šè©±ã‚’çµ‚äº†ã—ã¾ã—ãŸã€‚"
    else:
        pass

    if should_stop:
        if st.session_state.active == True:
            st.success(end_message)
            with st.form("evaluation_form"):
                st.subheader("â‘¥è©•ä¾¡ãƒ•ã‚©ãƒ¼ãƒ ")
                name = st.text_input(
                    "ã‚ãªãŸã®åå‰ã‚„ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒãƒ¼ãƒ ç­‰ï¼ˆè¢«é¨“è€…åŒºåˆ¥ç”¨ï¼‰"
                )
                grices_maxim = st.multiselect(
                    "ãƒ­ãƒœãƒƒãƒˆã®ç™ºè¨€ã«é–¢ã—ã¦ã€ä»¥ä¸‹ã®å†…å®¹ã®ä¸­ã§å½“ã¦ã¯ã¾ã‚‹ã‚‚ã®ãŒã‚ã‚Œã°é¸ã‚“ã§ãã ã•ã„ã€‚ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰",
                    [
                        "å˜˜ã‚„è™šå½ã®æƒ…å ±ã‚’è¿°ã¹ãŸ",
                        "è³ªå•ãƒ»æƒ…å ±æä¾›ãŒå¤šã™ãã‚‹ã¾ãŸã¯å°‘ãªã™ãã‚‹",
                        "ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ã®ã«é–¢ä¿‚ã®ãªã„ç™ºè¨€ãŒã‚ã£ãŸ",
                        "ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒæ˜ç¢ºã§ãªã‹ã£ãŸï¼ˆä½•ã¨ç­”ãˆã‚Œã°ã„ã„ã‹ã‚ã‹ã‚‰ãªã„è³ªå•ãŒã‚ã£ãŸç­‰ï¼‰",
                        "ç‰¹ã«ãªã—",
                    ]
                )
                kindness = st.radio(
                    "ãƒ­ãƒœãƒƒãƒˆã¯ã‚ãªãŸã«å¯¾ã—ã¦ã©ã‚Œãã‚‰ã„ã€Œè¦ªåˆ‡ã•/ä¸å¯§ã•ã€ã‚’æŒã£ã¦æ¥ã—ã¦ã„ã¾ã—ãŸã‹ï¼Ÿ",
                    ["éå¸¸ã«è¦ªåˆ‡ã ã£ãŸ", "ã¾ã‚ã¾ã‚è¦ªåˆ‡ã ã£ãŸ", "ã©ã¡ã‚‰ã¨ã‚‚ã„ãˆãªã„", "ã‚ã¾ã‚Šè¦ªåˆ‡ã§ãªã‹ã£ãŸ", "å…¨ãè¦ªåˆ‡ã§ãªã‹ã£ãŸ"],
                    horizontal=True
                )
                pleasantness = st.radio(
                    "ãƒ­ãƒœãƒƒãƒˆã¨ã®ä¼šè©±ã¯ã©ã‚Œãã‚‰ã„ã€Œæ„‰å¿«ã•ã€ã‚’æ„Ÿã˜ã¾ã—ãŸã‹ï¼Ÿ",
                    ["éå¸¸ã«æ„‰å¿«ã ã£ãŸ", "ã¾ã‚ã¾ã‚æ„‰å¿«ã ã£ãŸ", "ã©ã¡ã‚‰ã¨ã‚‚ã„ãˆãªã„", "å°‘ã—ä¸æ„‰å¿«ã ã£ãŸ", "ã¨ã¦ã‚‚ä¸æ„‰å¿«ã ã£ãŸ"],
                    horizontal=True
                )
                familiarity = st.radio(
                    "ãƒ­ãƒœãƒƒãƒˆã«ã©ã‚Œãã‚‰ã„ã€Œè¦ªè¿‘æ„Ÿ/è¦ªã—ã¿ã‚„ã™ã•ï¼ˆ=å¿ƒç†çš„è·é›¢æ„Ÿã®è¿‘ã•ï¼‰ã€ã‚’æŒã¡ã¾ã—ãŸã‹ï¼Ÿ",
                    ["å¼·ãæŒã£ãŸ", "ã¾ã‚ã¾ã‚æŒã£ãŸ", "ã©ã¡ã‚‰ã¨ã‚‚ã„ãˆãªã„", "ã‚ã¾ã‚ŠæŒã£ã¦ãªã„", "å…¨ãæŒã£ã¦ã„ãªã„"],
                    horizontal=True
                )
                social_presence = st.radio(
                    "å¯¾è©±ã®ç›¸æ‰‹ãŒãã“ã«å­˜åœ¨ã—ã€è‡ªåˆ†ã¨åŒã˜ç©ºé–“ã‚’å…±æœ‰ã—ã¦ã„ã‚‹ã€ã‚ã‚‹ã„ã¯è‡ªåˆ†ã¨é–¢ã‚ã£ã¦ã„ã‚‹æ„Ÿè¦šã€Œã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ—ãƒ¬ã‚¼ãƒ³ã‚¹ï¼ˆ=å­˜åœ¨æ„Ÿï¼‰ã€ã‚’ã©ã‚Œãã‚‰ã„æŒã¡ã¾ã—ãŸã‹ï¼Ÿ",
                    ["å¼·ãæŒã£ãŸ", "ã¾ã‚ã¾ã‚æŒã£ãŸ", "ã©ã¡ã‚‰ã¨ã‚‚ã„ãˆãªã„", "ã‚ã¾ã‚ŠæŒã£ã¦ãªã„", "å…¨ãæŒã£ã¦ã„ãªã„"],
                    horizontal=True
                )
                security = st.radio(
                    "ãƒ­ãƒœãƒƒãƒˆã«å¯¾ã—ã¦ã©ã‚Œãã‚‰ã„ã€Œå®‰å¿ƒæ„Ÿ/ä¿¡é ¼æ„Ÿã€ã‚’æŒã¡ã¾ã—ãŸã‹ï¼Ÿ",
                    ["å¼·ãæŒã£ãŸ", "ã¾ã‚ã¾ã‚æŒã£ãŸ", "ã©ã¡ã‚‰ã¨ã‚‚ã„ãˆãªã„", "ã‚ã¾ã‚ŠæŒã£ã¦ãªã„", "å…¨ãæŒã£ã¦ã„ãªã„"],
                    horizontal=True
                )
                impression = st.text_input(
                    "AIã¨ã®ä¼šè©±ã‚„ã€ãƒ­ãƒœãƒƒãƒˆã®è¡Œå‹•è¨ˆç”»ã«ã¤ã„ã¦ã€Œå°è±¡ã«æ®‹ã£ãŸã“ã¨ã€ãŒã‚ã‚Œã°ãŠé¡˜ã„ã—ã¾ã™ã€‚"
                )
                free = st.text_input(
                    "ãã®ä»–ã«ä½•ã‹æ„Ÿã˜ãŸã“ã¨ãŒã‚ã‚Œã°ãŠé¡˜ã„ã—ã¾ã™ã€‚"
                )

                st.markdown("###### SUSï¼ˆã‚·ã‚¹ãƒ†ãƒ ãƒ¦ãƒ¼ã‚¶ãƒ“ãƒªãƒ†ã‚£å°ºåº¦ï¼‰")
                sus_scores = {}
                sus_option_labels = [label for label, _ in SUS_OPTIONS]
                sus_value_map = dict(SUS_OPTIONS)
                for key, question in SUS_QUESTIONS:
                    choice = st.radio(
                        question,
                        sus_option_labels,
                        horizontal=True,
                        key=f"{key}_experiment2",
                    )
                    sus_scores[key] = sus_value_map.get(choice)

                st.markdown("###### NASA TLXï¼ˆ1 = ä½ã„ ï¼ 5 = é«˜ã„ï¼‰")
                nasa_scores = {}
                for key, question in NASA_TLX_QUESTIONS:
                    nasa_scores[key] = st.slider(
                        question,
                        min_value=1,
                        max_value=5,
                        value=3,
                        step=1,
                        format="%d",
                        key=f"{key}_experiment2",
                    )

                st.markdown("###### Godspeed ãƒ­ãƒœãƒƒãƒˆã®å°è±¡ã«ã¤ã„ã¦")
                st.markdown("**ãƒ»äººé–“ã‚‰ã—ã•ï¼ˆAnthropomorphismï¼‰**: ä»¥ä¸‹ã®ã‚¹ã‚±ãƒ¼ãƒ«ã«åŸºã¥ã„ã¦ã“ã®ãƒ­ãƒœãƒƒãƒˆã®å°è±¡ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚")
                godspeed_anthroporphism_scores = {}
                for key, question in GodSpeed_anthroporphism_QUESTIONS:
                    godspeed_anthroporphism_scores[key] = st.slider(
                        question,
                        min_value=1,
                        max_value=5,
                        value=3,
                        step=1,
                        format="%d",
                        key=f"{key}_experiment2",
                    )
                st.markdown("**ãƒ»ç”Ÿå‘½æ„Ÿï¼ˆAnimacyï¼‰**: ä»¥ä¸‹ã®ã‚¹ã‚±ãƒ¼ãƒ«ã«åŸºã¥ã„ã¦ã“ã®ãƒ­ãƒœãƒƒãƒˆã®å°è±¡ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚")
                godspeed_animacy_scores = {}
                for key, question in GodSpeed_animacy_QUESTIONS:
                    godspeed_animacy_scores[key] = st.slider(
                        question,
                        min_value=1,
                        max_value=5,
                        value=3,
                        step=1,
                        format="%d",
                        key=f"{key}_experiment2",
                    )
                st.markdown("**ãƒ»å¥½æ„Ÿåº¦ï¼ˆLikeabilityï¼‰**: ä»¥ä¸‹ã®ã‚¹ã‚±ãƒ¼ãƒ«ã«åŸºã¥ã„ã¦ã“ã®ãƒ­ãƒœãƒƒãƒˆã®å°è±¡ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚")
                godspeed_likeability_scores = {}
                for key, question in GodSpeed_likebility_QUESTIONS:
                    godspeed_likeability_scores[key] = st.slider(
                        question,
                        min_value=1,
                        max_value=5,
                        value=3,
                        step=1,
                        format="%d",
                        key=f"{key}_experiment2",
                    )
                st.markdown("**ãƒ»çŸ¥èƒ½ã®çŸ¥è¦šï¼ˆPerceived Intelligenceï¼‰**: ä»¥ä¸‹ã®ã‚¹ã‚±ãƒ¼ãƒ«ã«åŸºã¥ã„ã¦ã‚ãªãŸã®å¿ƒã®çŠ¶æ…‹ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚")
                godspeed_intelligence_scores = {}
                for key, question in GodSpeed_perceived_intelligence_QUESTIONS:
                    godspeed_intelligence_scores[key] = st.slider(
                        question,
                        min_value=1,
                        max_value=5,
                        value=3,
                        step=1,
                        format="%d",
                        key=f"{key}_experiment2",
                    )
                st.markdown("**ãƒ»å®‰å…¨æ€§ã®çŸ¥è¦šï¼ˆPerceived Safetyï¼‰**")
                godspeed_safety_scores = {}
                for key, question in GodSpeed_perceived_safety_QUESTIONS:
                    godspeed_safety_scores[key] = st.slider(
                        question,
                        min_value=1,
                        max_value=5,
                        value=3,
                        step=1,
                        format="%d",
                        key=f"{key}_experiment2",
                    )

                impression = st.text_input(
                    "AIã¨ã®ä¼šè©±ã‚„ã€ãƒ­ãƒœãƒƒãƒˆã®è¡Œå‹•è¨ˆç”»ã«ã¤ã„ã¦ã€Œå°è±¡ã«æ®‹ã£ãŸã“ã¨ã€ãŒã‚ã‚Œã°ãŠé¡˜ã„ã—ã¾ã™ã€‚"
                )
                free = st.text_input(
                    "ãã®ä»–ã«ä½•ã‹æ„Ÿã˜ãŸã“ã¨ãŒã‚ã‚Œã°ãŠé¡˜ã„ã—ã¾ã™ã€‚"
                )

                submitted = st.form_submit_button("è©•ä¾¡ã‚’ä¿å­˜")

            if submitted:
                st.warning("è©•ä¾¡ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼é©å®œä¼‘æ†©ã‚’ã¨ã£ã¦ãã ã•ã„â˜•")
                scores = {
                    "name": name,
                    "impression": impression,
                    "free": free,
                }
                # scores.update(sus_scores)
                scores.update(nasa_scores)
                scores.update(godspeed_anthroporphism_scores)
                scores.update(godspeed_animacy_scores)
                scores.update(godspeed_likeability_scores)
                scores.update(godspeed_intelligence_scores)
                scores.update(godspeed_safety_scores)
                termination_label = (
                    "ã‚¿ã‚¹ã‚¯å®Œäº†ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚Œã¾ã—ãŸ"
                    if st.session_state.get("force_end")
                    else ""
                )
                save_experiment_2_result(
                    scores,
                    termination_label=termination_label,
                )
                st.session_state.active = False
                st.session_state["experiment2_followup_prompt"] = True
                st.session_state.pop("experiment2_followup_choice", None)

    st.markdown("#### ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°")
    cols1 = st.columns([2, 1])
    with cols1[0]:
        st.markdown("**ğŸ¤”ã€Œå®Ÿè¡Œã—ã¾ã™ã€ã®ã‚ã¨ãƒ­ãƒœãƒƒãƒˆã®å®Ÿè¡ŒãŒå§‹ã¾ã‚‰ãªã„å ´åˆâ†’**")
    with cols1[1]:
        if st.button("â–¶ï¸å®Ÿè¡Œã‚’å§‹ã‚ã‚‹", key="manual_request_next_plan"):
            next_plan_request = "è¡Œå‹•è¨ˆç”»ã‚‚å‡ºåŠ›ã—ã¦"
            context.append({"role": "user", "content": next_plan_request})
            st.chat_message("user").write(next_plan_request)
            st.session_state.trigger_llm_call = True
            st.rerun()
    cols2 = st.columns([2, 1])
    with cols2[0]:
        st.markdown("**ğŸš¨ãƒã‚°ãŒèµ·ããŸå ´åˆï¼ˆLLMã‹ã‚‰ã®å›ç­”ãŒãªã„ç­‰ï¼‰â†’**")
    with cols2[1]:
        if st.button("âš ï¸ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆ", key="reset_conv"):
            save_conversation_history_to_firestore(
                "ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ",
                metadata={"experiment_page": PROMPT_GROUP},
            )
            _reset_conversation_state(system_prompt)
            st.rerun()
    cols = st.columns([2, 1])
    with cols[0]:
        st.markdown("**ğŸ˜Šãƒ­ãƒœãƒƒãƒˆã¨ã®ã‚¿ã‚¹ã‚¯ãŒå®Œäº†ã—ãŸå ´åˆâ†’**")
    with cols[1]:
        if st.button("âœ…ã‚¿ã‚¹ã‚¯å®Œäº†ï¼", key="force_end_button"):
            st.session_state.force_end = True
            st.rerun()
    if st.session_state.get("experiment2_followup_prompt"):
        if NEXT_PAGE:
            if st.button("æ¬¡ã®å®Ÿé¨“ã¸â†’", key="followup_no", type="primary"):
                st.session_state["experiment2_followup_prompt"] = False
                st.session_state.pop("experiment2_followup_choice", None)
                _reset_conversation_state(system_prompt)
                st.switch_page(NEXT_PAGE)
        else:
            st.info("ãŠç–²ã‚Œã•ã¾ã§ã—ãŸã€‚ã“ã‚Œã§å…¨ã¦ã®å®Ÿé¨“ãŒçµ‚äº†ã§ã™ã€‚")
        # if st.button("ğŸ™†â€â™‚ï¸ã¯ã„ â†’ å®Ÿé¨“çµ‚äº†", key="followup_yes", type="primary"):
        #     st.session_state["experiment2_followup_prompt"] = False
        #     st.session_state.pop("experiment2_followup_choice", None)
        #     st.success("å®Ÿé¨“ãŠç–²ã‚Œæ§˜ã§ã—ãŸï¼ã”å”åŠ›ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚")
        #     st.balloons()

app()
