import json
import os
import random
import re

import joblib
import streamlit as st
import streamlit.components.v1 as components
from consent import (
    apply_sidebar_hiding,
    configure_page,
    require_consent,
    should_hide_sidebar,
)
from dotenv import load_dotenv

from api import (
    SYSTEM_PROMPT_FRIENDLY,
    SYSTEM_PROMPT_PRATFALL,
    SYSTEM_PROMPT_STANDARD,
    build_bootstrap_user_message,
    client,
)
from jsonl import predict_with_model, save_experiment_2_result
from move_functions import move_to, pick_object, place_object_next_to, place_object_on
from run_and_show import run_plan_and_show, show_clarifying_question, show_function_sequence
from image_task_sets import (
    build_task_set_choices,
    extract_task_lines,
    load_image_task_sets,
    resolve_image_paths,
)
from two_classify import prepare_data  # æ—¢å­˜é–¢æ•°ã‚’åˆ©ç”¨

load_dotenv()


configure_page(hide_sidebar_for_participant=True)


SCROLL_RESET_FLAG_KEY = "experiment2_scroll_reset_done"
ACTIVE_PAGE_STATE_KEY = "current_active_page"
ACTIVE_PAGE_VALUE = "experiment_2"


def _scroll_to_top_on_first_load() -> None:
    if st.session_state.get(ACTIVE_PAGE_STATE_KEY) != ACTIVE_PAGE_VALUE:
        st.session_state.pop(SCROLL_RESET_FLAG_KEY, None)

    if not st.session_state.get(SCROLL_RESET_FLAG_KEY):
        components.html(
            """
            <script>
            const doc = window.parent ? window.parent.document : document;
            const main = doc ? doc.querySelector('section.main') : null;
            if (main) {
                main.scrollTo(0, 0);
            } else {
                window.scrollTo(0, 0);
            }
            </script>
            """,
            height=0,
        )
        st.session_state[SCROLL_RESET_FLAG_KEY] = True

    st.session_state[ACTIVE_PAGE_STATE_KEY] = ACTIVE_PAGE_VALUE


def _render_back_to_top_button() -> None:
    components.html(
        """
        <style>
        .scroll-to-top-btn {
            position: fixed;
            bottom: 2rem;
            right: 2rem;
            z-index: 99999;
            background-color: #0F9D58;
            color: #ffffff;
            border: none;
            border-radius: 9999px;
            width: 3rem;
            height: 3rem;
            font-size: 1.5rem;
            cursor: pointer;
            box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3);
        }

        .scroll-to-top-btn:hover {
            background-color: #0c7a45;
        }
        </style>
        <button class="scroll-to-top-btn" onclick="(function() {
            const doc = window.parent ? window.parent.document : document;
            const main = doc ? doc.querySelector('section.main') : null;
            if (main) {
                main.scrollTo({ top: 0, behavior: 'smooth' });
            } else {
                window.scrollTo({ top: 0, behavior: 'smooth' });
            }
        })()" aria-label="ãƒšãƒ¼ã‚¸ã®æœ€ä¸Šéƒ¨ã¸ç§»å‹•">â–²</button>
        """,
        height=0,
    )

def _reset_conversation_state(system_prompt: str) -> None:
    """Reset conversation-related session state for experiment 1."""

    st.session_state.context = [{"role": "system", "content": system_prompt}]
    st.session_state.active = True
    st.session_state.conv_log = {
        "label": "",
        "clarifying_steps": []
    }
    st.session_state.saved_jsonl = []
    st.session_state.turn_count = 0
    st.session_state.force_end = False
    # st.session_state.end_reason = []
    st.session_state["chat_input_history"] = []
    st.session_state["experiment2_followup_prompt"] = False
    st.session_state.pop("experiment2_followup_choice", None)
    _update_random_task_selection(
        "experiment2_selected_task_label",
        "experiment2_task_labels",
        "experiment2_label_to_key",
        "experiment2_selected_task_set",
    )

def _update_random_task_selection(label_key: str, labels_key: str, mapping_key: str, set_key: str) -> None:
    """Select a new task label at random and update related session state."""

    labels = st.session_state.get(labels_key) or []
    if not labels:
        return

    current_label = st.session_state.get(label_key)
    candidates = [label for label in labels if label != current_label] or labels
    new_label = random.choice(candidates)

    st.session_state[label_key] = new_label
    label_to_key = st.session_state.get(mapping_key) or {}
    st.session_state[set_key] = label_to_key.get(new_label)

TAG_RE = re.compile(r"</?([A-Za-z0-9_]+)(\s[^>]*)?>")

def strip_tags(text: str) -> str:
    return TAG_RE.sub("", text or "").strip()

def extract_between(tag: str, text: str) -> str | None:
    m = re.search(fr"<{tag}>([\s\S]*?)</{tag}>", text or "", re.IGNORECASE)
    return m.group(1).strip() if m else None

def run_plan_and_show(reply: str):
    """<Plan> ... </Plan> ã‚’è¦‹ã¤ã‘ã¦å®Ÿè¡Œã—ã€çµæœã‚’è¡¨ç¤º"""
    plan_match = re.search(r"<Plan>(.*?)</Plan>", reply, re.S)
    if not plan_match:
        return
    steps = re.findall(r"<Step>(.*?)</Step>", plan_match.group(1))
    if not steps:
        return

    with st.expander("Plan å®Ÿè¡Œãƒ­ã‚°", expanded=True):
        for step in steps:
            try:
                result = eval(step)  # ä¾‹: move_to(1.0, 2.0)
                st.write(f"âœ… `{step}` â†’ **{result}**")
            except Exception as e:
                st.write(f"âš ï¸ `{step}` ã®å®Ÿè¡Œã§ã‚¨ãƒ©ãƒ¼: {e}")

def finalize_and_render_plan(label: str):
    """ä¼šè©±çµ‚äº†æ™‚ã«è¡Œå‹•è¨ˆç”»ã‚’ã¾ã¨ã‚ã¦ç”»é¢è¡¨ç¤º"""
    # final_answer ã®æ±ºå®š
    last_assistant = next((m for m in reversed(st.session_state.context) if m["role"] == "assistant"), None)
    final_answer = extract_between("FinalAnswer", last_assistant["content"]) if last_assistant else None
    if not final_answer and last_assistant:
        final_answer = strip_tags(last_assistant["content"])

    st.session_state.conv_log["final_answer"] = final_answer or ""
    st.session_state.conv_log["label"] = "sufficient" if label == "sufficient" else "insufficient"

    # question_label ãŒ None ã®ã‚¹ãƒ†ãƒƒãƒ—ã¯ç¶™ç¶šãŒç„¡ã‘ã‚Œã° insufficient ã§åŸ‹ã‚ã‚‹
    for s in st.session_state.conv_log["clarifying_steps"]:
        if s["question_label"] is None:
            s["question_label"] = "insufficient"

    st.subheader("ä¼šè©±ã‚µãƒãƒªï¼ˆJSONï¼‰")
    st.code(
        json.dumps(st.session_state.conv_log, ensure_ascii=False, indent=2),
        language="json"
    )

def _build_text_for_model(instruction: str, function_sequence: str, information: str) -> str:
    # å­¦ç¿’æ™‚(two_classify.py)ã® prepare_data ã¨åŒã˜æ¥é ­è¾ãƒ»çµåˆé †ã«åˆã‚ã›ã‚‹
    parts = []
    if instruction.strip():
        parts.append(f"Instruction: {instruction.strip()}")
    if function_sequence.strip():
        parts.append(f"FunctionSequence: {function_sequence.strip()}")
    if information.strip():
        parts.append(f"Information: {information.strip()}")
    return " | ".join(parts)

def _extract_between(tag: str, text: str) -> str | None:
    m = re.search(fr"<{tag}>([\s\S]*?)</{tag}>", text or "", re.IGNORECASE)
    return m.group(1).strip() if m else ""

def get_critic_label(context):
    # 1) å…¥åŠ›æŠ½å‡ºï¼ˆæœ€æ–°ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè©±ã¨ç›´è¿‘ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆå‡ºåŠ›ã‹ã‚‰ FS/Informationï¼‰
    instruction = next((m.get("content","") for m in context if m.get("role")=="user"), "")
    last_assistant = next((m.get("content","") for m in reversed(context) if m.get("role")=="assistant"), "")
    function_sequence = _extract_between("FunctionSequence", last_assistant) or ""
    information      = _extract_between("Information",      last_assistant) or ""

    text = _build_text_for_model(instruction, function_sequence, information)

    # 2) ãƒ¢ãƒ‡ãƒ«+ä¿å­˜é–¾å€¤ã®ãƒ­ãƒ¼ãƒ‰ï¼ˆå¾Œæ–¹äº’æ›ï¼šæ—§ãƒ¢ãƒ‡ãƒ«ã¯é–¾å€¤0.5æ‰±ã„ï¼‰
    model_path = st.session_state.get("model_path", "models/critic_model_latest.joblib")
    obj = joblib.load(model_path)
    if isinstance(obj, dict):
        model = obj.get("model", obj)
        saved_th = float(obj.get("threshold", 0.5))
    else:
        model = obj
        saved_th = 0.5

    # 3) ç¢ºç‡è¨ˆç®—
    if hasattr(model, "predict_proba"):
        p = float(model.predict_proba([text])[0, 1])
    elif hasattr(model, "decision_function"):
        import numpy as np
        z = model.decision_function([text])[0]
        p = float(1 / (1 + np.exp(-z)))
    else:
        p = float(model.predict([text])[0])

    # 4) èª¤æ¤œçŸ¥å¯¾ç­–ï¼šæœ€ä½é–¾å€¤ï¼‹é«˜ä¿¡é ¼ãƒãƒ¼ã‚¸ãƒ³ï¼‹ã‚¬ãƒ¼ãƒ‰
    th_min  = float(st.session_state.get("critic_min_threshold", 0.60))  # â†å¿…è¦ã«å¿œã˜ã¦0.65ã€œ0.70ã‚‚å¯
    margin  = float(st.session_state.get("critic_margin", 0.15))
    th_eff  = max(saved_th, th_min)

    has_plan = bool(function_sequence.strip())
    turns    = int(st.session_state.get("turn_count", 0))
    high_conf = (p >= th_eff + margin)

    label = "sufficient" if (p >= th_eff and (high_conf or has_plan or turns >= 2)) else "insufficient"

    # ãƒ‡ãƒãƒƒã‚°ç”¨ã«ä¿æŒ
    st.session_state["critic_debug"] = {
        "p": p, "saved_th": saved_th, "th_eff": th_eff, "margin": margin,
        "has_plan": has_plan, "turns": turns, "label": label
    }
    return label

def app():
    require_consent()
    _scroll_to_top_on_first_load()
    _render_back_to_top_button()
    # st.title("LLMATCH Criticãƒ‡ãƒ¢ã‚¢ãƒ—ãƒª")
    st.markdown("### å®Ÿé¨“2 ç•°ãªã‚‹ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—ã®æ¯”è¼ƒ")

    if should_hide_sidebar():
        apply_sidebar_hiding()

    prompt_options = {
        "1": SYSTEM_PROMPT_STANDARD,
        "2": SYSTEM_PROMPT_FRIENDLY,
        "3": SYSTEM_PROMPT_PRATFALL,
    }
    prompt_keys = list(prompt_options.keys())
    if "prompt_label" not in st.session_state:
        st.session_state["prompt_label"] = random.choice(prompt_keys)

    default_prompt_label = st.session_state["prompt_label"]
    prompt_label = st.selectbox(
        "### â‘ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé¸æŠï¼ˆè‡ªå‹•ï¼‰",
        prompt_keys,
        index=prompt_keys.index(default_prompt_label)
        if default_prompt_label in prompt_keys
        else 0,
    )
    system_prompt = prompt_options[prompt_label]
    st.session_state["prompt_label"] = prompt_label

    st.write("â€»ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¦ã‚‚ã“ã®é¸æŠã¯å¤‰ã‚ã‚Šã¾ã›ã‚“ã€‚")
    st.session_state.setdefault("critic_min_threshold", 0.60)

    with st.expander("è©•ä¾¡ãƒ¢ãƒ‡ãƒ«ãƒ»ã‚¿ã‚¹ã‚¯èª¿æ•´ï¼ˆä»»æ„ï¼‰", expanded=False):
        # è©•ä¾¡ãƒ¢ãƒ‡ãƒ« selectbox
        model_files = sorted(
            f for f in os.listdir("models") if f.endswith(".joblib")
        )
        if model_files:
            latest_model = max(
                model_files,
                key=lambda f: os.path.getmtime(os.path.join("models", f)),
            )
            stored_model = st.session_state.get("model_path")
            current_model = os.path.basename(stored_model) if stored_model else None
            if current_model not in model_files:
                current_model = latest_model
            selected_model = st.selectbox(
                "è©•ä¾¡ãƒ¢ãƒ‡ãƒ«ï¼ˆè‡ªå‹•ï¼‰",
                model_files,
                index=model_files.index(current_model),
            )
            st.session_state["model_path"] = os.path.join("models", selected_model)

        st.session_state["critic_min_threshold"] = st.slider("critic_min_threshold", 0.5, 0.9, 0.60, 0.01)
        st.session_state["critic_margin"]       = st.slider("critic_margin", 0.0, 0.3, 0.15, 0.01)

        use_force = st.checkbox("ã—ãã„å€¤ã‚’ä¸Šæ›¸ãã™ã‚‹ï¼ˆforceï¼‰", value=True)
        if use_force:
            st.session_state["critic_force_threshold"] = st.slider("force_threshold", 0.50, 0.90, 0.60, 0.01)
        else:
            st.session_state.pop("critic_force_threshold", None)

        task_sets = load_image_task_sets()
        if not task_sets:
            st.warning("å†™çœŸã¨ã‚¿ã‚¹ã‚¯ã®ã‚»ãƒƒãƒˆãŒä¿å­˜ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã¾ãšã€å†™çœŸã¨ã‚¿ã‚¹ã‚¯ã®é¸å®šãƒ»ä¿å­˜ã€ãƒšãƒ¼ã‚¸ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚")
            st.session_state["selected_image_paths"] = []
            st.session_state["experiment2_selected_task_set"] = None
            st.session_state["experiment2_task_labels"] = []
            st.session_state["experiment2_label_to_key"] = {}
        else:
            choice_pairs = build_task_set_choices(task_sets)
            labels = [label for label, _ in choice_pairs]
            label_to_key = {label: key for label, key in choice_pairs}

            st.session_state["experiment2_task_labels"] = labels
            st.session_state["experiment2_label_to_key"] = label_to_key

            if not labels:
                st.warning("ä¿å­˜æ¸ˆã¿ã®ã‚¿ã‚¹ã‚¯ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
                st.session_state["selected_image_paths"] = []
                st.session_state["experiment2_selected_task_set"] = None
                st.session_state["experiment2_task_labels"] = []
                st.session_state["experiment2_label_to_key"] = {}
                payload = {}
            else:
                stored_label = st.session_state.get("experiment2_selected_task_label")
                if stored_label not in labels:
                    stored_label = random.choice(labels)
                selected_label = st.selectbox(
                    "ã‚¿ã‚¹ã‚¯",
                    labels,
                    index=labels.index(stored_label),
                )
                st.session_state["experiment2_selected_task_label"] = selected_label
                selected_task_name = label_to_key.get(selected_label)
                st.session_state["experiment2_selected_task_set"] = selected_task_name
                payload = task_sets.get(selected_task_name, {}) if selected_task_name else {}
        house = payload.get("house") if isinstance(payload, dict) else ""
        room = payload.get("room") if isinstance(payload, dict) else ""
        meta_lines = []

        task_lines = extract_task_lines(payload)

    st.markdown("#### â‘¡æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚¹ã‚¯")
    st.write("ä¸‹ã®ã‚¿ã‚¹ã‚¯ã‚’ãã®ã¾ã¾ç”»é¢ä¸‹éƒ¨ã®ãƒãƒ£ãƒƒãƒˆã«å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    if task_lines:
        for line in task_lines:
            st.info(f"{line}")
    else:
        st.info("ã‚¿ã‚¹ã‚¯ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    image_candidates = []
    if isinstance(payload, dict):
        image_candidates = [str(p) for p in payload.get("images", []) if isinstance(p, str)]

    existing_images, missing_images = resolve_image_paths(image_candidates)

    st.session_state["selected_image_paths"] = existing_images

    if missing_images:
        st.warning(
            "ä»¥ä¸‹ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: " + ", ".join(missing_images)
        )

    st.markdown("#### â‘¢æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ã‚’è¡Œã†å ´æ‰€")
    if house:
        meta_lines.append(f"å®¶: {house}")
    if room:
        meta_lines.append(f"éƒ¨å±‹: {room}")
    if meta_lines:
        st.write(" / ".join(meta_lines))
    if existing_images:
        for path in existing_images:
            st.image(path, caption=os.path.basename(path))
    else:
        st.info("ç”»åƒãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    # 1) ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆæœŸåŒ–ï¼ˆsystemã ã‘å…ˆã«å…¥ã‚Œã¦ä¿æŒï¼‰
    if (
        "context" not in st.session_state
        or st.session_state.get("system_prompt") != system_prompt
    ):
        st.session_state["context"] = [{"role": "system", "content": system_prompt}]
        st.session_state["system_prompt"] = system_prompt
        st.session_state.conv_log = {
            "final_answer": "",
            "label": "",
            "clarifying_steps": []
        }
        st.session_state["chat_input_history"] = []
        st.session_state.turn_count = 0
        st.session_state.force_end = False
        st.session_state.end_reason = []
        st.session_state.active = True
    if "active" not in st.session_state:
        st.session_state.active = True
    if "turn_count" not in st.session_state:
        st.session_state.turn_count = 0
    if "force_end" not in st.session_state:
        st.session_state.force_end = False
    if "end_reason" not in st.session_state:
        st.session_state.end_reason = []
    if "chat_input_history" not in st.session_state:
        st.session_state["chat_input_history"] = []
    if "experiment2_followup_prompt" not in st.session_state:
        st.session_state["experiment2_followup_prompt"] = False

    st.markdown("#### â‘£ãƒ­ãƒœãƒƒãƒˆã¨ã®ä¼šè©±")
    st.write("æœ€åˆã«â‘¡ã®ã‚¿ã‚¹ã‚¯ã‚’å…¥åŠ›ã—ã€â‘¢ã®å†™çœŸã‚’è¦‹ãªãŒã‚‰ãƒ­ãƒœãƒƒãƒˆã®è³ªå•ã«å¯¾ã—ã¦ç­”ãˆã¦ãã ã•ã„ã€‚" \
    "è³ªå•ã•ã‚ŒãŸæƒ…å ±ãŒå†™çœŸã«ãªã„å ´åˆã¯ã€\"ä»®æƒ³ã®æƒ…å ±\"ã‚’ç­”ãˆã¦æ§‹ã„ã¾ã›ã‚“ã€‚" \
    "è‡ªå‹•ã§è©•ä¾¡ãƒ•ã‚©ãƒ¼ãƒ ãŒè¡¨ç¤ºã•ã‚Œã‚‹ã¾ã§ä¼šè©±ã‚’ç¶šã‘ã¦ãã ã•ã„ã€‚")
    context = st.session_state["context"]

    message = st.chat_message("assistant")
    message.write("ã“ã‚“ã«ã¡ã¯ã€ç§ã¯å®¶åº­ç”¨ãƒ­ãƒœãƒƒãƒˆã§ã™ï¼ã‚ãªãŸã®æŒ‡ç¤ºã«å¾“ã£ã¦è¡Œå‹•ã—ã¾ã™ã€‚")
    should_stop = False
    if should_stop:
        user_input = None
    elif st.session_state.get("force_end"):
        user_input = None
    else:
        user_input = st.chat_input("ãƒ­ãƒœãƒƒãƒˆã¸ã®å›ç­”ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", key="experiment_2_chat_input")
        if user_input:
            st.session_state["chat_input_history"].append(user_input)
    if user_input:
        context.append({"role": "user", "content": user_input})
        selected_paths = st.session_state.get("selected_image_paths", [])
        if selected_paths:
            context.append(
                build_bootstrap_user_message(
                    text="Here are the selected images. Use them for scene understanding and disambiguation.",
                    local_image_paths=selected_paths,
                )
            )
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=context
        )
        reply = response.choices[0].message.content.strip()
        print("Assistant:", reply)
        context.append({"role": "assistant", "content": reply})
        print("context: ", context)
        st.session_state.turn_count += 1
        
    # ç”»é¢ä¸‹éƒ¨ã«å±¥æ­´ã‚’å…¨è¡¨ç¤ºï¼ˆsystemã¯çœãï¼‰
    last_assistant_idx = max((i for i, m in enumerate(context) if m["role"] == "assistant"), default=None)
    
    for i, msg in enumerate(context):
        if msg["role"] == "system":
            continue
        with st.chat_message(msg["role"]):
            st.write(msg["content"])
            if msg["role"] == "assistant":
                if i == last_assistant_idx and "<FunctionSequence>" in msg["content"]:
                    run_plan_and_show(msg["content"])
                show_function_sequence(msg["content"])
                show_clarifying_question(msg["content"])
    assistant_messages = [m for m in context if m["role"] == "assistant"]
    if assistant_messages:
        label, p, th = predict_with_model()
        st.caption(f"è©•ä¾¡ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬: {label} (p={p:.3f}, th={th:.3f})")
    else:
        label, p, th = None, None, None
        st.caption("è©•ä¾¡ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬: ---")

    last_assistant_content = assistant_messages[-1]["content"] if assistant_messages else ""
    has_plan = "<FunctionSequence>" in last_assistant_content
    high_conf = (p is not None and th is not None and p >= th + 0.15)

    # should_stop åˆ¤å®šï¼ˆæ—¢å­˜ã®ã¾ã¾ï¼‰
    end_message = ""
    if st.session_state.get("force_end"):
        should_stop = True
        end_message = "ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä¼šè©±ã‚’çµ‚äº†ã—ã¾ã—ãŸã€‚"
    else:
        if label == "sufficient" and (has_plan or high_conf or st.session_state.turn_count >= 2):
            should_stop = True
            end_message = "ãƒ¢ãƒ‡ãƒ«ãŒsufficientã‚’å‡ºåŠ›ã—ãŸãŸã‚çµ‚äº†ã—ã¾ã™ã€‚"

    if should_stop:
        if st.session_state.active == True:
            st.success(end_message)
            with st.form("evaluation_form"):
                st.subheader("â‘¤è©•ä¾¡ãƒ•ã‚©ãƒ¼ãƒ ")
                name = st.text_input(
                    "ã‚ãªãŸã®åå‰ã‚„ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒãƒ¼ãƒ ç­‰ï¼ˆè¢«é¨“è€…åŒºåˆ¥ç”¨ï¼‰"
                )
                success = st.radio(
                    "è¡Œå‹•è¨ˆç”»ãŒå®Ÿè¡Œã•ã‚ŒãŸã¨ã—ã¦ã€ãƒ­ãƒœãƒƒãƒˆã¯æˆåŠŸã—ã¾ã™ã‹ï¼Ÿ", 
                    ["æˆåŠŸã™ã‚‹", "æˆåŠŸã—ãªã„"], 
                    horizontal=True
                )
                failure_reason = st.multiselect(
                    "æˆåŠŸã—ãªã„å ´åˆã€ãã®ç†ç”±ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰",
                    [
                        "é–¢æ•°ãŒä¸é©åˆ‡ãƒ»ä¸è¶³ã—ã¦ã„ã‚‹",
                        "å¤‰æ•°ãŒä¸é©åˆ‡ãƒ»å…·ä½“çš„ã§ãªã„",
                        "è™šå½ã®æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹",
                        "ä¼šè©±ã®ä¸­ã§å‡ºã¦ããŸå¿…è¦ãªæƒ…å ±ã‚’å«ã‚“ã§ã„ãªã„",
                        "è¤‡æ•°ã®ã‚‚ã®ãŒã‚ã‚‹ä¸­ã§é©åˆ‡ãªã‚‚ã®ãŒé¸ã¹ãªã„",
                        "ä»¥ä¸Šã®ç†ç”±ä»¥å¤–", 
                        "æˆåŠŸã™ã‚‹",
                    ]
                )
                failure_reason_others = st.text_input(
                    "å‰ã®è³ªå•ã§ã€Œä»¥ä¸Šã®ç†ç”±ä»¥å¤–ã€ã‚’é¸ã‚“ã æ–¹ã¯ãã®å†…å®¹ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚"
                )
                grices_maxim = st.multiselect(
                    "ãƒ­ãƒœãƒƒãƒˆã®ç™ºè¨€ã«é–¢ã—ã¦ã€ä»¥ä¸‹ã®å†…å®¹ã®ä¸­ã§å½“ã¦ã¯ã¾ã‚‹ã‚‚ã®ãŒã‚ã‚Œã°é¸ã‚“ã§ãã ã•ã„ã€‚ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰",
                    [
                        "å˜˜ã‚„è™šå½ã®æƒ…å ±ã‚’è¿°ã¹ãŸ",
                        "è³ªå•ãƒ»æƒ…å ±æä¾›ãŒå¤šã™ãã‚‹ã¾ãŸã¯å°‘ãªã™ãã‚‹",
                        "ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ã®ã«é–¢ä¿‚ã®ãªã„ç™ºè¨€ãŒã‚ã£ãŸ",
                        "ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒæ˜ç¢ºã§ãªã‹ã£ãŸï¼ˆä½•ã¨ç­”ãˆã‚Œã°ã„ã„ã‹ã‚ã‹ã‚‰ãªã„è³ªå•ãŒã‚ã£ãŸç­‰ï¼‰",
                        "ç‰¹ã«ãªã—",
                    ]
                )
                kindness = st.radio(
                    "ãƒ­ãƒœãƒƒãƒˆã¯ã‚ãªãŸã«å¯¾ã—ã¦ã©ã‚Œãã‚‰ã„ã€Œè¦ªåˆ‡ã•/ä¸å¯§ã•ã€ã‚’æŒã£ã¦æ¥ã—ã¦ã„ã¾ã—ãŸã‹ï¼Ÿ",
                    ["éå¸¸ã«è¦ªåˆ‡ã ã£ãŸ", "ã¾ã‚ã¾ã‚è¦ªåˆ‡ã ã£ãŸ", "ã©ã¡ã‚‰ã¨ã‚‚ã„ãˆãªã„", "ã‚ã¾ã‚Šè¦ªåˆ‡ã§ãªã‹ã£ãŸ", "å…¨ãè¦ªåˆ‡ã§ãªã‹ã£ãŸ"],
                    horizontal=True
                )
                pleasantness = st.radio(
                    "ãƒ­ãƒœãƒƒãƒˆã¨ã®ä¼šè©±ã¯ã©ã‚Œãã‚‰ã„ã€Œæ„‰å¿«ã•ã€ã‚’æ„Ÿã˜ã¾ã—ãŸã‹ï¼Ÿ",
                    ["éå¸¸ã«æ„‰å¿«ã ã£ãŸ", "ã¾ã‚ã¾ã‚æ„‰å¿«ã ã£ãŸ", "ã©ã¡ã‚‰ã¨ã‚‚ã„ãˆãªã„", "å°‘ã—ä¸æ„‰å¿«ã ã£ãŸ", "ã¨ã¦ã‚‚ä¸æ„‰å¿«ã ã£ãŸ"],
                    horizontal=True
                )
                st.write("ã€Œè¦ªè¿‘æ„Ÿï¼å¿ƒç†çš„è·é›¢ã®è¿‘ã•ã€ã€Œã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ»ãƒ—ãƒ¬ã‚¼ãƒ³ã‚¹ï¼ç›¸æ‰‹ãŒâ€œãã“ã«ã„ã‚‹â€æ„Ÿè¦šã€ã¨å®šç¾©ã—ã¾ã™ã€‚")
                familiarity = st.radio(
                    "ãƒ­ãƒœãƒƒãƒˆã«ã©ã‚Œãã‚‰ã„ã€Œè¦ªè¿‘æ„Ÿ/è¦ªã—ã¿ã‚„ã™ã•ï¼ˆ=å¿ƒç†çš„è·é›¢æ„Ÿã®è¿‘ã•ï¼‰ã€ã‚’æŒã¡ã¾ã—ãŸã‹ï¼Ÿ",
                    ["å¼·ãæŒã£ãŸ", "ã¾ã‚ã¾ã‚æŒã£ãŸ", "ã©ã¡ã‚‰ã¨ã‚‚ã„ãˆãªã„", "ã‚ã¾ã‚ŠæŒã£ã¦ãªã„", "å…¨ãæŒã£ã¦ã„ãªã„"],
                    horizontal=True
                )
                social_presence = st.radio(
                    "å¯¾è©±ã®ç›¸æ‰‹ãŒãã“ã«å­˜åœ¨ã—ã€è‡ªåˆ†ã¨åŒã˜ç©ºé–“ã‚’å…±æœ‰ã—ã¦ã„ã‚‹ã€ã‚ã‚‹ã„ã¯è‡ªåˆ†ã¨é–¢ã‚ã£ã¦ã„ã‚‹æ„Ÿè¦šã€Œã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ—ãƒ¬ã‚¼ãƒ³ã‚¹ï¼ˆ=å­˜åœ¨æ„Ÿï¼‰ã€ã‚’ã©ã‚Œãã‚‰ã„æŒã¡ã¾ã—ãŸã‹ï¼Ÿ",
                    ["å¼·ãæŒã£ãŸ", "ã¾ã‚ã¾ã‚æŒã£ãŸ", "ã©ã¡ã‚‰ã¨ã‚‚ã„ãˆãªã„", "ã‚ã¾ã‚ŠæŒã£ã¦ãªã„", "å…¨ãæŒã£ã¦ã„ãªã„"],
                    horizontal=True
                )
                security = st.radio(
                    "ãƒ­ãƒœãƒƒãƒˆã«å¯¾ã—ã¦ã©ã‚Œãã‚‰ã„ã€Œå®‰å¿ƒæ„Ÿ/ä¿¡é ¼æ„Ÿã€ã‚’æŒã¡ã¾ã—ãŸã‹ï¼Ÿ",
                    ["å¼·ãæŒã£ãŸ", "ã¾ã‚ã¾ã‚æŒã£ãŸ", "ã©ã¡ã‚‰ã¨ã‚‚ã„ãˆãªã„", "ã‚ã¾ã‚ŠæŒã£ã¦ãªã„", "å…¨ãæŒã£ã¦ã„ãªã„"],
                    horizontal=True
                )
                impression = st.text_input(
                    "ã€Œå°è±¡ã«æ®‹ã£ãŸã“ã¨ã€ãŒã‚ã‚Œã°ãŠé¡˜ã„ã—ã¾ã™ã€‚"
                )
                improvement = st.text_input(
                    "ã€Œæ”¹å–„ã—ã¦ã»ã—ã„ç‚¹ã€ãŒã‚ã‚Œã°ãŠé¡˜ã„ã—ã¾ã™ã€‚"
                )
                free = st.text_input(
                    "ãã®ä»–ã«ä½•ã‹æ„Ÿã˜ãŸã“ã¨ãŒã‚ã‚Œã°ãŠé¡˜ã„ã—ã¾ã™ã€‚"
                )
                submitted = st.form_submit_button("è©•ä¾¡ã‚’ä¿å­˜")

            if submitted:
                st.warning("è©•ä¾¡ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼é©å®œä¼‘æ†©ã‚’ã¨ã£ã¦ãã ã•ã„â˜•")
                scores = {
                    "name": name,
                    "success": success,
                    "failure_reason": failure_reason,
                    "failure_reason_others": failure_reason_others,
                    "grices_maxim": grices_maxim,
                    "kindness": kindness,
                    "pleasantness": pleasantness,
                    "familiarity": familiarity,
                    "social_presence": social_presence,
                    "security": security,
                    "impression": impression,
                    "improvement": improvement,
                    "free": free,
                }
                termination_label = "ä¼šè©±ã‚’å¼·åˆ¶çš„ã«çµ‚äº†" if st.session_state.get("force_end") else ""
                selected_reasons = st.session_state.get("end_reason", [])
                if isinstance(selected_reasons, str):
                    termination_reason = selected_reasons
                else:
                    termination_reason = "ã€".join(selected_reasons)
                save_experiment_2_result(
                    scores,
                    termination_reason,
                    termination_label,
                )
                st.session_state.active = False
                st.session_state["experiment2_followup_prompt"] = True
                st.session_state.pop("experiment2_followup_choice", None)

    cols = st.columns([1, 1, 2])
    with cols[0]:
        if st.button("âš ï¸ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆ", key="reset_conv"):
            _reset_conversation_state(system_prompt)
            st.rerun()
    with cols[1]:
        if st.button("ğŸš¨ä¼šè©±ã‚’çµ‚äº†", key="force_end_button"):
            st.session_state.force_end = True
            st.session_state.end_reason = st.session_state.get("end_reason", [])
            st.rerun()
    with cols[2]:
        st.multiselect(
            "ä¼šè©±ã‚’çµ‚äº†ã—ãŸã„ç†ç”±",
            [
                "è¡Œå‹•è¨ˆç”»ã¯å®Ÿè¡Œå¯èƒ½ã§ã•ã‚‰ãªã‚‹è³ªå•ã¯ä¸è¦",
                "åŒã˜è³ªå•ãŒç¹°ã‚Šè¿”ã•ã‚Œã‚‹",
                "è¨ˆç”»ã¯ç¢ºå®šã—ã¦ã„ã‚‹",
                "LLMã‹ã‚‰è³ªå•ã•ã‚Œãªã„",
                "ãã®ä»–",
            ],
            key="end_reason",
        )
    if st.session_state.get("experiment2_followup_prompt"):
        st.markdown("**3ã¤ã®ãƒ¢ãƒ¼ãƒ‰** ã§1å›ãšã¤å®Ÿé¨“ã‚’çµ‚ãˆã¾ã—ãŸã‹ï¼Ÿ")
        if st.button("ğŸ™…â€â™‚ï¸ã„ã„ãˆ â†’ â‘ ã®ãƒ¢ãƒ¼ãƒ‰ã‚’å¤‰ãˆã¦å†åº¦å®Ÿé¨“", key="followup_no", type="primary"):
            st.session_state["experiment2_followup_prompt"] = False
            st.session_state.pop("experiment2_followup_choice", None)
            _reset_conversation_state(system_prompt)
            st.rerun()
        if st.button("ğŸ™†â€â™‚ï¸ã¯ã„ â†’ å®Ÿé¨“çµ‚äº†", key="followup_yes", type="primary"):
            st.session_state["experiment2_followup_prompt"] = False
            st.session_state.pop("experiment2_followup_choice", None)
            st.success("å®Ÿé¨“ãŠç–²ã‚Œæ§˜ã§ã—ãŸï¼ã”å”åŠ›ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚")
            st.balloons()
app()
