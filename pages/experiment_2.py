import json
import os
import random
import re

import joblib
import streamlit as st
from dotenv import load_dotenv

from api import (
    SYSTEM_PROMPT_FRIENDLY,
    SYSTEM_PROMPT_PRATFALL,
    SYSTEM_PROMPT_STANDARD,
    build_bootstrap_user_message,
    client,
)
from jsonl import predict_with_model, save_experiment_2_result
from move_functions import move_to, pick_object, place_object_next_to, place_object_on
from run_and_show import run_plan_and_show, show_clarifying_question, show_function_sequence
from image_task_sets import (
    build_task_set_choices,
    extract_task_lines,
    load_image_task_sets,
    resolve_image_paths,
)

from two_classify import prepare_data  # æ—¢å­˜é–¢æ•°ã‚’åˆ©ç”¨

load_dotenv()

TAG_RE = re.compile(r"</?([A-Za-z0-9_]+)(\s[^>]*)?>")

def strip_tags(text: str) -> str:
    return TAG_RE.sub("", text or "").strip()

def extract_between(tag: str, text: str) -> str | None:
    m = re.search(fr"<{tag}>([\s\S]*?)</{tag}>", text or "", re.IGNORECASE)
    return m.group(1).strip() if m else None

def run_plan_and_show(reply: str):
    """<Plan> ... </Plan> ã‚’è¦‹ã¤ã‘ã¦å®Ÿè¡Œã—ã€çµæœã‚’è¡¨ç¤º"""
    plan_match = re.search(r"<Plan>(.*?)</Plan>", reply, re.S)
    if not plan_match:
        return
    steps = re.findall(r"<Step>(.*?)</Step>", plan_match.group(1))
    if not steps:
        return

    with st.expander("Plan å®Ÿè¡Œãƒ­ã‚°", expanded=True):
        for step in steps:
            try:
                result = eval(step)  # ä¾‹: move_to(1.0, 2.0)
                st.write(f"âœ… `{step}` â†’ **{result}**")
            except Exception as e:
                st.write(f"âš ï¸ `{step}` ã®å®Ÿè¡Œã§ã‚¨ãƒ©ãƒ¼: {e}")

def finalize_and_render_plan(label: str):
    """ä¼šè©±çµ‚äº†æ™‚ã«è¡Œå‹•è¨ˆç”»ã‚’ã¾ã¨ã‚ã¦ç”»é¢è¡¨ç¤º"""
    # final_answer ã®æ±ºå®š
    last_assistant = next((m for m in reversed(st.session_state.context) if m["role"] == "assistant"), None)
    final_answer = extract_between("FinalAnswer", last_assistant["content"]) if last_assistant else None
    if not final_answer and last_assistant:
        final_answer = strip_tags(last_assistant["content"])

    st.session_state.conv_log["final_answer"] = final_answer or ""
    st.session_state.conv_log["label"] = "sufficient" if label == "sufficient" else "insufficient"

    # question_label ãŒ None ã®ã‚¹ãƒ†ãƒƒãƒ—ã¯ç¶™ç¶šãŒç„¡ã‘ã‚Œã° insufficient ã§åŸ‹ã‚ã‚‹
    for s in st.session_state.conv_log["clarifying_steps"]:
        if s["question_label"] is None:
            s["question_label"] = "insufficient"

    st.subheader("ä¼šè©±ã‚µãƒãƒªï¼ˆJSONï¼‰")
    st.code(
        json.dumps(st.session_state.conv_log, ensure_ascii=False, indent=2),
        language="json"
    )

def get_critic_label(context):
    # contextã‹ã‚‰åˆ¤å®šç”¨ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ
    instruction = next((m["content"] for m in context if m["role"] == "user"), "")
    clarifying_steps = []
    for m in context:
        if m["role"] == "assistant":
            q = extract_between("llm_question", m["content"]) or ""
            a = extract_between("user_answer", m["content"]) or ""
            if q and a:
                clarifying_steps.append({"llm_question": q, "user_answer": a})
    ex = {"instruction": instruction, "clarifying_steps": clarifying_steps, "label": "unknown"}
    texts, _ = prepare_data([ex])
    model_path = st.session_state.get("model_path", "models/critic_model_20250903_053907.joblib")
    model = joblib.load(model_path)
    pred = model.predict(texts)
    return "sufficient" if pred[0] == 1 else "insufficient"

def app():
    st.title("LLMATCH Criticãƒ‡ãƒ¢ã‚¢ãƒ—ãƒª")
    st.subheader("å®Ÿé¨“2 ç•°ãªã‚‹ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—ã®æ¯”è¼ƒ")
    
    st.sidebar.subheader("è¡Œå‹•è¨ˆç”»ã§ä½¿ç”¨ã•ã‚Œã‚‹é–¢æ•°")
    st.sidebar.markdown(
    """
    - **move_to(room_name:str)**  
    æŒ‡å®šã—ãŸéƒ¨å±‹ã¸ãƒ­ãƒœãƒƒãƒˆã‚’ç§»å‹•ã—ã¾ã™ã€‚

    - **pick_object(object:str)**  
    æŒ‡å®šã—ãŸç‰©ä½“ã‚’ã¤ã‹ã¿ã¾ã™ã€‚

    - **place_object_next_to(object:str, target:str)**  
    æŒ‡å®šã—ãŸç‰©ä½“ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®æ¨ªã«ç½®ãã¾ã™ã€‚

    - **place_object_on(object:str, target:str)**  
    æŒ‡å®šã—ãŸç‰©ä½“ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ä¸Šã«ç½®ãã¾ã™ã€‚

    - **place_object_in(object:str, target:str)**  
    æŒ‡å®šã—ãŸç‰©ä½“ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ä¸­ã«å…¥ã‚Œã¾ã™ã€‚

    - **detect_object(object:str)**  
    æŒ‡å®šã—ãŸç‰©ä½“ã‚’æ¤œå‡ºã—ã¾ã™ã€‚

    - **search_about(object:str)**  
    æŒ‡å®šã—ãŸç‰©ä½“ã«é–¢ã™ã‚‹æƒ…å ±ã‚’æ¤œç´¢ã—ã¾ã™ã€‚

    - **push(object:str)**  
    æŒ‡å®šã—ãŸç‰©ä½“ã‚’æŠ¼ã—ã¾ã™ã€‚

    - **say(text:str)**  
    æŒ‡å®šã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ç™ºè©±ã—ã¾ã™ã€‚
    """
    )

    prompt_options = {
        "1": SYSTEM_PROMPT_STANDARD,
        "2": SYSTEM_PROMPT_FRIENDLY,
        "3": SYSTEM_PROMPT_PRATFALL,
    }
    prompt_keys = list(prompt_options.keys())
    if "prompt_label" not in st.session_state:
        st.session_state["prompt_label"] = random.choice(prompt_keys)

    default_prompt_label = st.session_state["prompt_label"]
    prompt_label = st.selectbox(
        "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆè‡ªå‹•ï¼‰",
        prompt_keys,
        index=prompt_keys.index(default_prompt_label)
        if default_prompt_label in prompt_keys
        else 0,
    )
    system_prompt = prompt_options[prompt_label]
    st.session_state["prompt_label"] = prompt_label

    with st.expander("è©•ä¾¡ãƒ¢ãƒ‡ãƒ«ãƒ»ã‚¿ã‚¹ã‚¯èª¿æ•´ï¼ˆä»»æ„ï¼‰", expanded=False):
        # è©•ä¾¡ãƒ¢ãƒ‡ãƒ« selectbox
        model_files = sorted(
            f for f in os.listdir("models") if f.endswith(".joblib")
        )
        if model_files:
            latest_model = max(
                model_files,
                key=lambda f: os.path.getmtime(os.path.join("models", f)),
            )
            stored_model = st.session_state.get("model_path")
            current_model = os.path.basename(stored_model) if stored_model else None
            if current_model not in model_files:
                current_model = latest_model
            selected_model = st.selectbox(
                "è©•ä¾¡ãƒ¢ãƒ‡ãƒ«ï¼ˆè‡ªå‹•ï¼‰",
                model_files,
                index=model_files.index(current_model),
            )
            st.session_state["model_path"] = os.path.join("models", selected_model)

        # ã‚¿ã‚¹ã‚¯ selectbox
        task_sets = load_image_task_sets()
        if not task_sets:
            st.warning("å†™çœŸã¨ã‚¿ã‚¹ã‚¯ã®ã‚»ãƒƒãƒˆãŒä¿å­˜ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã¾ãšã€å†™çœŸã¨ã‚¿ã‚¹ã‚¯ã®é¸å®šãƒ»ä¿å­˜ã€ãƒšãƒ¼ã‚¸ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚")
            st.session_state["selected_image_paths"] = []
            st.session_state["experiment2_selected_task_set"] = None
        else:
            choice_pairs = build_task_set_choices(task_sets)
            labels = [label for label, _ in choice_pairs]
            label_to_key = {label: key for label, key in choice_pairs}

            if not labels:
                st.warning("ä¿å­˜æ¸ˆã¿ã®ã‚¿ã‚¹ã‚¯ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
                st.session_state["selected_image_paths"] = []
                st.session_state["experiment2_selected_task_set"] = None
                payload = {}
            else:
                # ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ
                selected_label = random.choice(labels)
                st.selectbox("ã‚¿ã‚¹ã‚¯", labels, index=labels.index(selected_label))
                selected_task_name = label_to_key.get(selected_label)
                st.session_state["experiment2_selected_task_set"] = selected_task_name
                payload = task_sets.get(selected_task_name, {}) if selected_task_name else {}
        house = payload.get("house") if isinstance(payload, dict) else ""
        room = payload.get("room") if isinstance(payload, dict) else ""
        meta_lines = []

        task_lines = extract_task_lines(payload)

    st.markdown("### æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚¹ã‚¯")
    if task_lines:
        for line in task_lines:
            st.info(f"{line}")
    else:
        st.info("ã‚¿ã‚¹ã‚¯ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.write("â†’æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ã‚’ãã®ã¾ã¾ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«å…¥åŠ›ã—ã¦ãã ã•ã„ï¼")

    image_candidates = []
    if isinstance(payload, dict):
        image_candidates = [str(p) for p in payload.get("images", []) if isinstance(p, str)]

    existing_images, missing_images = resolve_image_paths(image_candidates)

    st.session_state["selected_image_paths"] = existing_images

    if missing_images:
        st.warning(
            "ä»¥ä¸‹ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: " + ", ".join(missing_images)
        )

    st.markdown("### æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ãŒè¡Œã‚ã‚Œã‚‹å ´æ‰€")
    if house:
        meta_lines.append(f"å®¶: {house}")
    if room:
        meta_lines.append(f"éƒ¨å±‹: {room}")
    if meta_lines:
        st.write(" / ".join(meta_lines))
    if existing_images:
        for path in existing_images:
            st.image(path, caption=os.path.basename(path))
    else:
        st.info("ç”»åƒãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    # 1) ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆæœŸåŒ–ï¼ˆsystemã ã‘å…ˆã«å…¥ã‚Œã¦ä¿æŒï¼‰
    if (
        "context" not in st.session_state
        or st.session_state.get("system_prompt") != system_prompt
    ):
        st.session_state["context"] = [{"role": "system", "content": system_prompt}]
        st.session_state["system_prompt"] = system_prompt
        st.session_state.conv_log = {
            "final_answer": "",
            "label": "",
            "clarifying_steps": []
        }
        st.session_state["chat_input_history"] = []
    if "active" not in st.session_state:
        st.session_state.active = True
    if "force_end" not in st.session_state:
        st.session_state.force_end = False
    if "end_reason" not in st.session_state:
        st.session_state.end_reason = ""
    if "chat_input_history" not in st.session_state:
        st.session_state["chat_input_history"] = []

    st.markdown("### ãƒ­ãƒœãƒƒãƒˆã¨ã®ä¼šè©±")
    st.write("æœ€åˆã«ã‚¿ã‚¹ã‚¯ã‚’å…¥åŠ›ã—ã€ä¸Šã®å†™çœŸã‚’è¦‹ãªãŒã‚‰ãƒ­ãƒœãƒƒãƒˆã®è³ªå•ã«å¯¾ã—ã¦ç­”ãˆã¦ãã ã•ã„ã€‚")
    context = st.session_state["context"]

    message = st.chat_message("assistant")
    message.write("ã“ã‚“ã«ã¡ã¯ã€ç§ã¯å®¶åº­ç”¨ãƒ­ãƒœãƒƒãƒˆã§ã™ï¼ã‚ãªãŸã®æŒ‡ç¤ºã«å¾“ã£ã¦è¡Œå‹•ã—ã¾ã™ã€‚")
    if st.session_state.get("force_end"):
        user_input = None
    else:
        user_input = st.chat_input("ãƒ­ãƒœãƒƒãƒˆã¸ã®æŒ‡ç¤ºã‚„å›ç­”ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        if user_input:
            st.session_state["chat_input_history"].append(user_input)
    if user_input:
        context.append({"role": "user", "content": user_input})
        selected_paths = st.session_state.get("selected_image_paths", [])
        if selected_paths:
            context.append(
                build_bootstrap_user_message(
                    text="Here are the selected images. Use them for scene understanding and disambiguation.",
                    local_image_paths=selected_paths,
                )
            )
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=context
        )
        reply = response.choices[0].message.content.strip()
        print("Assistant:", reply)
        context.append({"role": "assistant", "content": reply})
        print("context: ", context)

        run_plan_and_show(reply)

    # sufficientåˆ¤å®šãªã‚‰çµ‚äº†
    label = get_critic_label(context)
    if label == "sufficient":
        st.success("ã‚¯ãƒªãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ãŒã€Œååˆ†ã€ã¨åˆ¤å®šã—ãŸãŸã‚ä¼šè©±ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
        finalize_and_render_plan(label="sufficient")
        st.stop()

    # ç”»é¢ä¸‹éƒ¨ã«å±¥æ­´ã‚’å…¨è¡¨ç¤ºï¼ˆsystemã¯çœãï¼‰
    last_assistant_idx = max((i for i, m in enumerate(context) if m["role"] == "assistant"), default=None)
    
    for i, msg in enumerate(context):
        if msg["role"] == "system":
            continue
        with st.chat_message(msg["role"]):
            st.write(msg["content"])
            if msg["role"] == "assistant":
                if i == last_assistant_idx and "<FunctionSequence>" in msg["content"]:
                    run_plan_and_show(msg["content"])
                show_function_sequence(msg["content"])
                show_clarifying_question(msg["content"])
    label = predict_with_model()
    should_stop = False
    end_message = ""

    if st.session_state.get("force_end"):
        should_stop = True
        end_message = "ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä¼šè©±ã‚’å¼·åˆ¶çš„ã«çµ‚äº†ã—ã¾ã—ãŸã€‚"
    elif label == "sufficient":
        should_stop = True
        end_message = "ãƒ¢ãƒ‡ãƒ«ãŒsufficientã‚’å‡ºåŠ›ã—ãŸãŸã‚çµ‚äº†ã—ã¾ã™ã€‚"

    if should_stop:
        st.success(end_message)
        if st.session_state.active:
            with st.form("evaluation_form"):
                name = st.text_input(
                    "ã‚ãªãŸã®åå‰ã‚„ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒãƒ¼ãƒ ç­‰ï¼ˆè¢«é¨“è€…åŒºåˆ¥ç”¨ï¼‰"
                )
                success = st.radio(
                    "è¡Œå‹•è¨ˆç”»ãŒå®Ÿè¡Œã•ã‚ŒãŸã¨ã—ã¦ã€ãƒ­ãƒœãƒƒãƒˆã¯æˆåŠŸã—ã¾ã™ã‹ï¼Ÿ", 
                    ["æˆåŠŸã™ã‚‹", "æˆåŠŸã—ãªã„"], 
                    horizontal=True
                )
                failure_reason = st.multiselect(
                    "æˆåŠŸã—ãªã„å ´åˆã€ãã®ç†ç”±ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰",
                    [
                        "é–¢æ•°ãŒä¸é©åˆ‡ãƒ»ä¸è¶³ã—ã¦ã„ã‚‹",
                        "å¤‰æ•°ãŒä¸é©åˆ‡ãƒ»å…·ä½“çš„ã§ãªã„",
                        "è™šå½ã®æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹",
                        "ä¼šè©±ã®ä¸­ã§å‡ºã¦ããŸå¿…è¦ãªæƒ…å ±ã‚’å«ã‚“ã§ã„ãªã„",
                        "è¤‡æ•°ã®ã‚‚ã®ãŒã‚ã‚‹ä¸­ã§é©åˆ‡ãªã‚‚ã®ãŒé¸ã¹ãªã„",
                        "ä»¥ä¸Šã®ç†ç”±ä»¥å¤–", 
                        "æˆåŠŸã™ã‚‹"
                    ]
                )
                failure_reason_others = st.text_input(
                    "å‰ã®è³ªå•ã§ã€Œä»¥ä¸Šã®ç†ç”±ä»¥å¤–ã€ã‚’é¸ã‚“ã æ–¹ã¯ãã®å†…å®¹ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚"
                )
                grices_maxim = st.multiselect(
                    "ãƒ­ãƒœãƒƒãƒˆã®ç™ºè¨€ã«é–¢ã—ã¦ã€ä»¥ä¸‹ã®å†…å®¹ã®ä¸­ã§å½“ã¦ã¯ã¾ã‚‹ã‚‚ã®ãŒã‚ã‚Œã°é¸ã‚“ã§ãã ã•ã„ã€‚ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰",
                    [
                        "å˜˜ã‚„è™šå½ã®æƒ…å ±ã‚’è¿°ã¹ãŸ",
                        "è³ªå•ãƒ»æƒ…å ±æä¾›ãŒå¤šã™ãã‚‹ã¾ãŸã¯å°‘ãªã™ãã‚‹",
                        "ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ã®ã«é–¢ä¿‚ã®ãªã„ç™ºè¨€ãŒã‚ã£ãŸ",
                        "ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒæ˜ç¢ºã§ãªã‹ã£ãŸï¼ˆä½•ã¨ç­”ãˆã‚Œã°ã„ã„ã‹ã‚ã‹ã‚‰ãªã„è³ªå•ãŒã‚ã£ãŸç­‰ï¼‰"
                    ]
                )
                familiarity = st.radio(
                    "ãƒ­ãƒœãƒƒãƒˆã«ã©ã‚Œãã‚‰ã„è¦ªè¿‘æ„Ÿã‚’æŒã¡ã¾ã—ãŸã‹ï¼Ÿï¼ˆ1-4ï¼‰",
                    [1, 2, 3, 4],
                    horizontal=True
                )
                social_presence = st.radio(
                    "å¯¾è©±ã®ç›¸æ‰‹ãŒãã“ã«å­˜åœ¨ã—ã€è‡ªåˆ†ã¨åŒã˜ç©ºé–“ã‚’å…±æœ‰ã—ã¦ã„ã‚‹ã€ã‚ã‚‹ã„ã¯è‡ªåˆ†ã¨é–¢ã‚ã£ã¦ã„ã‚‹æ„Ÿè¦šï¼ˆã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ—ãƒ¬ã‚¼ãƒ³ã‚¹ï¼‰ã‚’ã©ã‚Œãã‚‰ã„æŒã¡ã¾ã—ãŸã‹ï¼Ÿï¼ˆ1-4ï¼‰",
                    [1, 2, 3, 4],
                    horizontal=True
                )
                free = st.text_input(
                    "ãã®ä»–ã«ä½•ã‹æ„Ÿã˜ãŸã“ã¨ãŒã‚ã‚Œã°ãŠé¡˜ã„ã—ã¾ã™ã€‚"
                )
                submitted = st.form_submit_button("è©•ä¾¡ã‚’ä¿å­˜")

            if submitted:
                scores = {
                    "name": name,
                    "success": success,
                    "failure_reason": failure_reason,
                    "failure_reason_others": failure_reason_others,
                    "grices_maxim": grices_maxim,
                    "familiarity": familiarity,
                    "social_presence": social_presence,
                    "free": free,
                }
                termination_label = "ä¼šè©±ã‚’å¼·åˆ¶çš„ã«çµ‚äº†" if st.session_state.get("force_end") else ""
                save_experiment_2_result(
                    scores,
                    st.session_state.get("end_reason", ""),
                    termination_label,
                )
                st.session_state.active = False

    cols = st.columns([1, 1, 2])
    with cols[0]:
        if st.button("âš ï¸ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆ", key="reset_conv"):
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’åˆæœŸåŒ–
            st.session_state.context = [{"role": "system", "content": system_prompt}]
            st.session_state.active = True
            st.session_state.conv_log = {
                "label": "",
                "clarifying_steps": []
            }
            st.session_state.saved_jsonl = []
            st.session_state.force_end = False
            st.session_state.end_reason = ""
            st.session_state["chat_input_history"] = []
            st.rerun()
    with cols[1]:
        if st.button("ğŸš¨ä¼šè©±ã‚’å¼·åˆ¶çš„ã«çµ‚äº†", key="force_end_button"):
            st.session_state.force_end = True
            st.session_state.end_reason = st.session_state.get("end_reason", "")
            st.rerun()
    with cols[2]:
        st.text_input("ä¼šè©±ã‚’çµ‚äº†ã—ãŸã„ç†ç”±", key="end_reason")

app()
